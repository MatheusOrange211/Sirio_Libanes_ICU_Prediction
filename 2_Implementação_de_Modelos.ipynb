{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 - Implementação de Modelos",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN4l01MqXS9xGJQjH37bu6O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatheusOrange211/Sirio_Libanes_ICU_Prediction/blob/main/2_Implementa%C3%A7%C3%A3o_de_Modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moJexAm3sVx5"
      },
      "source": [
        "Este trabalho foi desenvolvido por **Matheus Naranjo Corrêa**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qvYXf2kg6wS"
      },
      "source": [
        "# TESTANDO MODELOS PARA PREDIÇÃO DE PACIENTES QUE PRECISARÃO DE UTI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MmOw1xpj6sy"
      },
      "source": [
        "Conforme solicitado pela direção do Hospital Sírio Libanês ao departamento de Tecnologia e Dados, apresentaremos abaixo uma proposta de solução para o seguinte problema:\r\n",
        "\r\n",
        "**PROBLEMA**\r\n",
        "> A pandemia da SARS-COVID-19 (popularmente conhecido como coronavírus), vem causando grandes estresses nos sistemas de saúdes globais. Países com alta taxa de desenvolvimento vêm sofrendo com a falta de leitos de Unidade de Terapia Intensiva (UTI) na internação de seus pacientes, levando equipes médicas a terem que aplicar métodos de escolha severos, dando prioridade para os mais idosos e graves. Contudo, tais métodos não auxiliam na resolução do problema dado a alta taxa de contaminação existente, consequência das ondas de infecção que vêm sendo causadas em um efeito de *onda* ao redor do mundo. <br>\r\n",
        "Tal problema afeta também países emergentes e subdesenvolvidos, que geralmente já possuem sistemas de saúde superlotados, como no caso do Brasil. Infelizmente a superlotação e a falta de leitos já sobrecarregou sistemas de vários estados, como no caso do estado do Amazonas ([link da matéria](https://g1.globo.com/am/amazonas/noticia/2021/01/14/secretario-de-saude-do-am-fala-que-estado-vive-colapso-do-plano-logistico.ghtml)), onde pacientes não estão mais conseguindo acesso a UTI, assim como não possuem equipamentos básicos para a manutenção de vida, como oxigênio. <br>\r\n",
        "Com base nesses acontecimentos e até mesmo na prevenção de sobrecarga do sistema de saúde das redes privadas, o Hospital Sírio-Libanês, referência internacional em saúde, busca prevenir e até mesmo predizer, com base em dados clínicos de seus pacientes, conforme forem sendo admitidos no ambiente hospitalar, a necessidade ou não de internação nas UTIs nas próximas horas. A ideia por trás disso é conseguir desenvolver um modelo de aprendizagem de máquina, conhecido com **Machine Learning**, que consiga auxiliar a junta médica a tomar decisões referentes a necessidade ou não de internação na UTI para aquele paciente, usando as boas práticas de programação e respeitando a Lei Geral da Proteção de dados, conforme indica a lei federal Lei nº 13.709/2018."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktORiHxApnG-"
      },
      "source": [
        "Conforme analisado no notebook [Visualizando os Dados](https://github.com/MatheusOrange211/Sirio_Libanes_ICU_Prediction/blob/main/Visualizando_os_dados_Sirio_Libanes.ipynb), realizamos uma breve exploração acerca dos dados fornecidos pela equipe de pesquisa do hospital, buscando entender o que fora nos enviado e como deveriamos ir trabalhando com os dados. Ficou decidido, com base em análises (figura 4 - Internação em UTI pelo tempo de Admissão: Precisou de UTI?), que o melhor janela de admissão para se trabalhar era de até duas horas, uma vez que com ela, poderiamos tentar predizer mais cedo se o paciente necessitaria ou não de internação na UTI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QwVkvFLrZkz"
      },
      "source": [
        "Nessa segunda parte do projeto, optaremos por testar modelos de Machine Learning que ajudem no nosso problema de **classificação**. Inicialmente realizaremos a importação dos dados, sua limpeza (com funções criadas no notebook de visualização de dados e outras), separação dos dados para treino e teste, o treinamento com alguns algoritmos de classificação e por fim sua validação e implementação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oruTNNjEsPAB"
      },
      "source": [
        "# IMPORTANDO BIBLIOTECAS\r\n",
        "\r\n",
        "Importaremos as bibliotecas básicas usadas no desenvolvimento de análises e tratamento de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZKnzoD1gkhB"
      },
      "source": [
        "#Bibliotecas básicas para análises e visualização de dados\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "#---------------------------------------------------------\r\n",
        "#biblioteca para medição de tempo de execuções dos modelos\r\n",
        "import time \r\n",
        "#---------------------------------------------------------\r\n",
        "#biblioteca de Modelos de Machine Learning e ferramentas de auxilio\r\n",
        "#---------------------------------------------------------\r\n",
        "from sklearn import model_selection\r\n",
        "from sklearn.dummy import DummyClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from xgboost import XGBClassifier\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmG2AGYTs2Mh"
      },
      "source": [
        "# Dados\r\n",
        "\r\n",
        "Os dados fornecidos pela equipe de pesquisa do Hospital Sírio Libanês estão disponíves neste site: [Kaggle - Sírio-libanês](https://www.kaggle.com/S%C3%ADrio-Libanes/covid19). Uma explicação dos dados já fora feita no notebook anterior, logo, passaremos para outra parte.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "GptmTliGsnpk",
        "outputId": "fa72ead4-1f46-4cc1-fcc4-547749669740"
      },
      "source": [
        "dados = pd.read_excel(\"https://github.com/alura-cursos/covid-19-clinical/blob/main/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx?raw=true\")\r\n",
        "dados.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PATIENT_VISIT_IDENTIFIER</th>\n",
              "      <th>AGE_ABOVE65</th>\n",
              "      <th>AGE_PERCENTIL</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>DISEASE GROUPING 1</th>\n",
              "      <th>DISEASE GROUPING 2</th>\n",
              "      <th>DISEASE GROUPING 3</th>\n",
              "      <th>DISEASE GROUPING 4</th>\n",
              "      <th>DISEASE GROUPING 5</th>\n",
              "      <th>DISEASE GROUPING 6</th>\n",
              "      <th>HTN</th>\n",
              "      <th>IMMUNOCOMPROMISED</th>\n",
              "      <th>OTHER</th>\n",
              "      <th>ALBUMIN_MEDIAN</th>\n",
              "      <th>ALBUMIN_MEAN</th>\n",
              "      <th>ALBUMIN_MIN</th>\n",
              "      <th>ALBUMIN_MAX</th>\n",
              "      <th>ALBUMIN_DIFF</th>\n",
              "      <th>BE_ARTERIAL_MEDIAN</th>\n",
              "      <th>BE_ARTERIAL_MEAN</th>\n",
              "      <th>BE_ARTERIAL_MIN</th>\n",
              "      <th>BE_ARTERIAL_MAX</th>\n",
              "      <th>BE_ARTERIAL_DIFF</th>\n",
              "      <th>BE_VENOUS_MEDIAN</th>\n",
              "      <th>BE_VENOUS_MEAN</th>\n",
              "      <th>BE_VENOUS_MIN</th>\n",
              "      <th>BE_VENOUS_MAX</th>\n",
              "      <th>BE_VENOUS_DIFF</th>\n",
              "      <th>BIC_ARTERIAL_MEDIAN</th>\n",
              "      <th>BIC_ARTERIAL_MEAN</th>\n",
              "      <th>BIC_ARTERIAL_MIN</th>\n",
              "      <th>BIC_ARTERIAL_MAX</th>\n",
              "      <th>BIC_ARTERIAL_DIFF</th>\n",
              "      <th>BIC_VENOUS_MEDIAN</th>\n",
              "      <th>BIC_VENOUS_MEAN</th>\n",
              "      <th>BIC_VENOUS_MIN</th>\n",
              "      <th>BIC_VENOUS_MAX</th>\n",
              "      <th>BIC_VENOUS_DIFF</th>\n",
              "      <th>BILLIRUBIN_MEDIAN</th>\n",
              "      <th>BILLIRUBIN_MEAN</th>\n",
              "      <th>...</th>\n",
              "      <th>DIMER_MAX</th>\n",
              "      <th>DIMER_DIFF</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MEAN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MEAN</th>\n",
              "      <th>HEART_RATE_MEAN</th>\n",
              "      <th>RESPIRATORY_RATE_MEAN</th>\n",
              "      <th>TEMPERATURE_MEAN</th>\n",
              "      <th>OXYGEN_SATURATION_MEAN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MEDIAN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MEDIAN</th>\n",
              "      <th>HEART_RATE_MEDIAN</th>\n",
              "      <th>RESPIRATORY_RATE_MEDIAN</th>\n",
              "      <th>TEMPERATURE_MEDIAN</th>\n",
              "      <th>OXYGEN_SATURATION_MEDIAN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MIN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MIN</th>\n",
              "      <th>HEART_RATE_MIN</th>\n",
              "      <th>RESPIRATORY_RATE_MIN</th>\n",
              "      <th>TEMPERATURE_MIN</th>\n",
              "      <th>OXYGEN_SATURATION_MIN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MAX</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MAX</th>\n",
              "      <th>HEART_RATE_MAX</th>\n",
              "      <th>RESPIRATORY_RATE_MAX</th>\n",
              "      <th>TEMPERATURE_MAX</th>\n",
              "      <th>OXYGEN_SATURATION_MAX</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_DIFF</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_DIFF</th>\n",
              "      <th>HEART_RATE_DIFF</th>\n",
              "      <th>RESPIRATORY_RATE_DIFF</th>\n",
              "      <th>TEMPERATURE_DIFF</th>\n",
              "      <th>OXYGEN_SATURATION_DIFF</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_DIFF_REL</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_DIFF_REL</th>\n",
              "      <th>HEART_RATE_DIFF_REL</th>\n",
              "      <th>RESPIRATORY_RATE_DIFF_REL</th>\n",
              "      <th>TEMPERATURE_DIFF_REL</th>\n",
              "      <th>OXYGEN_SATURATION_DIFF_REL</th>\n",
              "      <th>WINDOW</th>\n",
              "      <th>ICU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.283019</td>\n",
              "      <td>-0.593220</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.283019</td>\n",
              "      <td>-0.586207</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.237113</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.162393</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>-0.247863</td>\n",
              "      <td>-0.459459</td>\n",
              "      <td>-0.432836</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>-0.420290</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0-2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.132075</td>\n",
              "      <td>-0.593220</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.132075</td>\n",
              "      <td>-0.586207</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.443299</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.025641</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.838384</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>-0.459459</td>\n",
              "      <td>-0.313433</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>0.246377</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>2-4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.994912</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4-6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.318681</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.275362</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>6-12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.979069</td>\n",
              "      <td>-0.979069</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.996762</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.243021</td>\n",
              "      <td>-0.338537</td>\n",
              "      <td>-0.213031</td>\n",
              "      <td>-0.317859</td>\n",
              "      <td>0.033779</td>\n",
              "      <td>0.665932</td>\n",
              "      <td>-0.283951</td>\n",
              "      <td>-0.376923</td>\n",
              "      <td>-0.188679</td>\n",
              "      <td>-0.379310</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>-0.340206</td>\n",
              "      <td>-0.4875</td>\n",
              "      <td>-0.572650</td>\n",
              "      <td>-0.857143</td>\n",
              "      <td>0.098901</td>\n",
              "      <td>0.797980</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>0.286486</td>\n",
              "      <td>0.298507</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.362319</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>-0.33913</td>\n",
              "      <td>0.325153</td>\n",
              "      <td>0.114504</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>-0.238095</td>\n",
              "      <td>-0.818182</td>\n",
              "      <td>-0.389967</td>\n",
              "      <td>0.407558</td>\n",
              "      <td>-0.230462</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>-0.242282</td>\n",
              "      <td>-0.814433</td>\n",
              "      <td>ABOVE_12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 231 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   PATIENT_VISIT_IDENTIFIER  AGE_ABOVE65  ...    WINDOW  ICU\n",
              "0                         0            1  ...       0-2    0\n",
              "1                         0            1  ...       2-4    0\n",
              "2                         0            1  ...       4-6    0\n",
              "3                         0            1  ...      6-12    0\n",
              "4                         0            1  ...  ABOVE_12    1\n",
              "\n",
              "[5 rows x 231 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw1v8gL6wj-i"
      },
      "source": [
        "#FUNÇÕES BÁSICAS - PREPARANDO OS DADOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z30xS1boxCZw"
      },
      "source": [
        "Abaixo temos funções que realizarão as limpezas iniciais dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSeda6p935ej"
      },
      "source": [
        "Função usada para nos mostrar um breve resumo do nosso DataFrame (Usada no notebook Visualizando dados)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu_fWN5g4C_Q"
      },
      "source": [
        "def resume_dataframe(dataset  : pd.DataFrame):\r\n",
        "  \r\n",
        "  data_nan = dataset.isnull().any().any() #retorno os dados Not a Number das colunas\r\n",
        "  dataset_types = list (set(dataset.dtypes.values)) #com o set realizo um \"filtro\" removendo dados repetidos\r\n",
        "  print(\"################ RESUMO BÁSICO ####################\\n\")\r\n",
        "  #shape nos retorna uma tupla com dois valores, sendo um referente a linhas e o outro a coluna, respectivamente.\r\n",
        "  print(f\"Quantidade de instâncias: {dataset.shape[0]} (linhas)\\nQuantidade de Atributos: {dataset.shape[1]} (colunas)\\n\")\r\n",
        "\r\n",
        "  if data_nan:\r\n",
        "    print(f\"Possui dados NaN ? {data_nan}\\nQuantidade de NaN totais: {dataset.isnull().sum().values.sum()}\\n\")\r\n",
        "  else:\r\n",
        "    print(\"Não há dados ausentes neste dataset\\n\")\r\n",
        "\r\n",
        "  print(f\"Tipos de  dados que temos :\\n{dataset_types}\\n\")\r\n",
        "  print(\"##################################################\\n\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyjYE5fOxV0o"
      },
      "source": [
        "Essa função divide nosso dataframe em 3 pedaços:\r\n",
        "* features continuas (contém grande parte das colunas de dados clínicos e NaN)\r\n",
        "* features categoricas (as 13 primeiras colunas do nosso DataFrame)\r\n",
        "* saida (as duas últimas colunas  - `WINDOW`e `ICU`)\r\n",
        "\r\n",
        "Aplica-se groupby para agrupar cada valor da coluna `PATIENT_VISIT_IDENTIFIER` e nela, aplicar, para as colunas continuas selecionadas, os métodos `bfill`e `fill` para assim preencher os dados faltantesm uma vez que por serem relacionados a saúde, não apresentam, no geral, grandes discrepâncias. Por último, agrupamos tudo novamente e reajustamos as colunas, por fim retornando os dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cOOj_6NtO_D"
      },
      "source": [
        "def preenche_tabela(dados):\r\n",
        "    features_continuas_colunas = dados.iloc[:, 13:-2].columns\r\n",
        "    features_continuas = dados.groupby(\"PATIENT_VISIT_IDENTIFIER\", as_index=False)[features_continuas_colunas]\\\r\n",
        "                          .fillna(method='bfill')\\\r\n",
        "                          .fillna(method='ffill')\r\n",
        "    features_categoricas = dados.iloc[:, :13]\r\n",
        "    saida = dados.iloc[:, -2:]\r\n",
        "    dados_finais = pd.concat([features_categoricas, features_continuas, saida], ignore_index=True,axis=1)\r\n",
        "    dados_finais.columns = dados.columns\r\n",
        "    return dados_finais"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmmfYZuDzgUq"
      },
      "source": [
        "Como trabalharemos com dados referentes a uma janela de até duas horas após a admissão, buscaremos filtrar e adicionar o valor 1 para pacientes que em algum momento foram para a UTI. Conforme explicado no notebook anterior (caso não tenha visto):<br>\r\n",
        ">Essa função é responsável por realizar um filtro do qual busca-se manter valores referentes a janela de até 2 duas horas. Aplicando-se esta função em um groupby, ocorrerá que os dados serão agrupados. Uma vez agrupados, faremos, por meio desta função, uma verificação onde se qualquer uma das linhas conferidas for igual a 1, ou seja, se em um agrupamento do paciente **x** em todos os períodos, se, por exemplo, na janela `0-4`, tivermos o valor de `ICU` == 1  (ou seja, um valor True), será aplicado nessa linha, da primeira janela de admissão (no caso, 0-2), o valor igual a 1 para a coluna ICU. Visualizando:\r\n",
        "\r\n",
        "\r\n",
        "| WINDOW  |ICU   |   \r\n",
        "|---------|------|\r\n",
        "| 0-2        | 0  | \r\n",
        "|     2-4    |  0 | \r\n",
        "|       4-6  |   1| \r\n",
        "|       6-12  |   0| \r\n",
        "\r\n",
        ">Veja como na janela de 4-6 horas, o paciente já foi para UTI. o que esta função fará é por o valor 1 logo na primeira Janela:\r\n",
        "\r\n",
        "| WINDOW  |ICU   |   \r\n",
        "|---------|------|\r\n",
        "| 0-2        | 1  | \r\n",
        "|     2-4    |  0 | \r\n",
        "|       4-6  |   0| \r\n",
        "|       6-12  |   0|\r\n",
        "\r\n",
        ">E assim, retornaremos apenas a primeira linha."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM_1aN0t0po-"
      },
      "source": [
        "Essa função agrupa todos os grupos de dados de um paciente e atribui o valor ICU == 1 na janela de até duas horas para assim pordemos trabalhar apenas com pacientes do quadro de até duas horas. Eis o motivo de termos jogado fora dados de pacientes com `ICU = 1` e `WINDOW = 0-2` logo de cara. Se a pessoa já entrou no hospital precisando de UTI, seus dados não servirão para o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyX8hyQGwqGb"
      },
      "source": [
        "def prepare_window(rows):\r\n",
        "    if(np.any(rows[\"ICU\"])):\r\n",
        "        rows.loc[rows[\"WINDOW\"]==\"0-2\", \"ICU\"] = 1\r\n",
        "    return rows.loc[rows[\"WINDOW\"] == \"0-2\"]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u8VY_JzWuoS"
      },
      "source": [
        "Nessa função, o que acontece é que passando nosso dataframe (contendo NaN e strings - não se preocupe quanto a isso), filtramos as colunas e ficamos apenas com as que são numéricas. Depois passamos o método de correlação e damos um .`pipe()` (com ele, a gente pode aplicar funções no DataFrame, por exemplo). Aplicamos um lambda e passamos um `np.tril()`. O que ele fará é retornar os valores maiores que -1 numa matrix de diagonal `k-therizada` (Leia a [documentação](https://numpy.org/doc/stable/reference/generated/numpy.tril.html) para um maior aprofundamento). Criamos as colunas e index e empilhamos as colunas que são geradas durante a correlação. Passando outro `pipe()`, retornamos apenas os valores que são maiores que o parâmetro que passamos na declaração da função. Por último damos um `query()` para realizar um filtro em valores que estão na coluna `level_0` e não em `level_1` ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INzjM6PbWuwp"
      },
      "source": [
        "def correlated_columns_harrison(dataset, threshold = 0.95):\r\n",
        "  df = dataset[dataset.describe().columns]  #fica-se apenas com as colunas que possuem valores numéricos\r\n",
        "  return (\r\n",
        "      df.corr().pipe(lambda df1: pd.DataFrame(np.tril(df1,k=-1),  \r\n",
        "                                              columns = df.columns,\r\n",
        "                                              index = df.columns,\r\n",
        "                                              )\r\n",
        "      ) \r\n",
        "      .stack()\r\n",
        "      .rename(\"pearson\")\r\n",
        "      .pipe(\r\n",
        "          lambda s: s[s.abs() >threshold].reset_index()\r\n",
        "      )\r\n",
        "      .query(\"level_0 not in level_1\")\r\n",
        "  )"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQCKVLFPXGr7"
      },
      "source": [
        "Nessa função, iremos criar uma lista com as colunas com valores correlacionados que serão descartadas. Para as duas colunas que ela possui, iremos dropar valores repetidos e adicionar os que sobram a uma lista que é retornada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAyHLWeSXG04"
      },
      "source": [
        "def descartar_colunas_correlacionadas(dataset: pd.DataFrame):\r\n",
        "    colunas_com_muita_correlacao = [] #cria-se uma lista vazia \r\n",
        "    for valor in dataset['level_0'].drop_duplicates().values: #dropa-se o nome duplicados de colunsa presentes na coluna level_0\r\n",
        "      colunas_com_muita_correlacao.append(valor) #adiciona-se os valores na lista\r\n",
        "    for valor in dataset['level_1'].drop_duplicates().values:#dropa-se o nome duplicados de colunsa presentes na coluna level_1\r\n",
        "      colunas_com_muita_correlacao.append(valor)  #adiciona-se os valores na lista\r\n",
        "    return colunas_com_muita_correlacao"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_5mGNNoaUFV"
      },
      "source": [
        "Técnica elaborada por Thiago Gonçalves e Alan Spadinni, conhecida popularmente na literatura alurística de programação como **tecnica Gondinni**, que consiste na criação de correlação de todas as linhas e, com exceção das primeiras 4 e últimas duas colunas do dataframe,  gerar a correlação  e transformação dos valores para absoluto. Depois busca-se selecionar os valores do *triângulo superior* que foram gerados nessa matriz de correlação, todos os valores são transformados para 1s, e depois aplicamos um k = 1 (que gera a divisão dos valores do triângulo superior),, é que aplicamos uma transformação para True nos valores que antes eram 1 , e False para os valores  0s. Dessa forma, quando aplicado o `where`, conseguiremos pegar os valores da matriz superior e assim termos as colunas correlacionas, sem ter a parte do triângulo inferior, que funciona como um espelho. <BR>\r\n",
        "Por último, realizando um list comprehenssion, buscaremos todas as colunas maiores que `valor_corte` e adicionamos a `excluir` que será  usada para dropar posteriormente todas as colunas maiores que o valor setado para `valor_corte`.\r\n",
        "\r\n",
        "<img src = \"https://static.mundoeducacao.uol.com.br/mundoeducacao/conteudo/matriz-triangular-superior.jpg\">\r\n",
        "\r\n",
        "Acima temos um exemplo de uma matriz onde de azul são os valores da diagonal (em azul) que sempre serão iguais a 1, pois são as mesmas colunas refletidas uma na outras , como por exemplo  COLUNA_1 X COLUNA_1 , onde ambas são a mesma coluna, logo é obvio que irão ter correlação perfeita igual a 1. <br>\r\n",
        "Em preto, temos o chamado triângulo superior, que é o que desejamos manter, e em vermelho, o chamado triângulo inferior, que será descartado por possuir os mesmos resultados do outro triângulo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVXXW2waaUMO"
      },
      "source": [
        "def remove_corr_var(dados,valor_corte = .95):\r\n",
        "\r\n",
        "  matriz_corr = dados.iloc[:,4:-2].corr().abs()\r\n",
        "  matrix_upper = matriz_corr.where(np.triu(np.ones(matriz_corr.shape),k=1).astype(np.bool))\r\n",
        "  excluir  = [ coluna for coluna in matrix_upper.columns if any(matrix_upper[coluna] > valor_corte)]\r\n",
        "\r\n",
        "  return dados.drop(excluir,axis=1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPsQ1Fz7Gnt7"
      },
      "source": [
        "Essa função irá executar os modelos:\r\n",
        "* DummyClassifier\r\n",
        "* LogisticRegression\r\n",
        "* DecisionTreeClassifier\r\n",
        "* KNeighborsClassifier\r\n",
        "* GaussianNB\r\n",
        "* SVC\r\n",
        "* RandomForestClassifier\r\n",
        "* XGBClassifier\r\n",
        "\r\n",
        "Passamos apenas o dataset que deverá ser particionado em treino e teste, depois com um laço de repetição, iremos obter os resultados de cada modelo para determinado conjunto de dados passados. A ideia é apenas ter uma visão inicial de como os dados estão funcionando, se logo de cara, já estão treinando bem, por isso não é passado parâmetros mais específicos para cada modelo, o que pode ocasionar a saída de **WARNINGS**. Contudo, pelos motivos explicados, isso é previsto. Por fim, temos a saída de uma lista com os valores AUC, desvio padrão (STD), e o tempo de execução."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeOuSEMoGn9v"
      },
      "source": [
        "def rodar_varios_modelos(dataset):\r\n",
        "  \r\n",
        "  x_columns = dataset.columns\r\n",
        "  x_columns = x_columns.drop([\"PATIENT_VISIT_IDENTIFIER\"])\r\n",
        "  y = dataset[\"ICU\"]\r\n",
        "  x = dataset[x_columns].drop([\"ICU\"], axis=1)\r\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y)\r\n",
        "\r\n",
        "  results = []\r\n",
        "  np.random.seed(415645)\r\n",
        "  for model in [DummyClassifier,LogisticRegression,DecisionTreeClassifier,KNeighborsClassifier,GaussianNB,\r\n",
        "                SVC,RandomForestClassifier,XGBClassifier]:\r\n",
        "\r\n",
        "                start_time  = time.time()\r\n",
        "\r\n",
        "                model_used = model()\r\n",
        "\r\n",
        "                kfold = StratifiedKFold(n_splits=5,shuffle=True)\r\n",
        "                val_score = model_selection.cross_val_score(model_used,x,y,scoring=\"roc_auc\",\r\n",
        "                                                            cv = kfold,)\r\n",
        "                \r\n",
        "                results.append(f\"{model.__name__:22} AUC:\\\r\n",
        "                {val_score.mean():.3f} STD: {val_score.std():.2f}     Tempo execução: {time.time() - start_time} seconds\")\r\n",
        "\r\n",
        "  return results"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pubBUIBJz_hu"
      },
      "source": [
        "# PREPARANDO O DATAFRAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5DAChSM4bcK"
      },
      "source": [
        "Antes de aplicar os modelos e ver qual possui melhor custo benefício, vamos preparar nosso dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a2l9bMM03bX"
      },
      "source": [
        "Cria-se a variável que armazanerá os dados formatados e previamente, limpos. Aqui, iremos também, realizar uma query por todas as colunas as linhas que possuem `WINDOW=='0-2' and ICU==1`, pois essas, serão eliminadas de imediado, dados que seus dados não nos servem. Realizamos um dropna para remover dados NaN restantes, caso haja."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "RRWoiczDwqEC",
        "outputId": "a759a93c-33f5-487e-8192-cb1e44420f31"
      },
      "source": [
        "dados_limpos = preenche_tabela(dados)\r\n",
        "a_remover = dados_limpos.query(\"WINDOW=='0-2' and ICU==1\")['PATIENT_VISIT_IDENTIFIER'].values\r\n",
        "dados_limpos = dados_limpos.query(\"PATIENT_VISIT_IDENTIFIER not in @a_remover\")\r\n",
        "dados_limpos = dados_limpos.dropna()\r\n",
        "dados_limpos.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PATIENT_VISIT_IDENTIFIER</th>\n",
              "      <th>AGE_ABOVE65</th>\n",
              "      <th>AGE_PERCENTIL</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>DISEASE GROUPING 1</th>\n",
              "      <th>DISEASE GROUPING 2</th>\n",
              "      <th>DISEASE GROUPING 3</th>\n",
              "      <th>DISEASE GROUPING 4</th>\n",
              "      <th>DISEASE GROUPING 5</th>\n",
              "      <th>DISEASE GROUPING 6</th>\n",
              "      <th>HTN</th>\n",
              "      <th>IMMUNOCOMPROMISED</th>\n",
              "      <th>OTHER</th>\n",
              "      <th>ALBUMIN_MEDIAN</th>\n",
              "      <th>ALBUMIN_MEAN</th>\n",
              "      <th>ALBUMIN_MIN</th>\n",
              "      <th>ALBUMIN_MAX</th>\n",
              "      <th>ALBUMIN_DIFF</th>\n",
              "      <th>BE_ARTERIAL_MEDIAN</th>\n",
              "      <th>BE_ARTERIAL_MEAN</th>\n",
              "      <th>BE_ARTERIAL_MIN</th>\n",
              "      <th>BE_ARTERIAL_MAX</th>\n",
              "      <th>BE_ARTERIAL_DIFF</th>\n",
              "      <th>BE_VENOUS_MEDIAN</th>\n",
              "      <th>BE_VENOUS_MEAN</th>\n",
              "      <th>BE_VENOUS_MIN</th>\n",
              "      <th>BE_VENOUS_MAX</th>\n",
              "      <th>BE_VENOUS_DIFF</th>\n",
              "      <th>BIC_ARTERIAL_MEDIAN</th>\n",
              "      <th>BIC_ARTERIAL_MEAN</th>\n",
              "      <th>BIC_ARTERIAL_MIN</th>\n",
              "      <th>BIC_ARTERIAL_MAX</th>\n",
              "      <th>BIC_ARTERIAL_DIFF</th>\n",
              "      <th>BIC_VENOUS_MEDIAN</th>\n",
              "      <th>BIC_VENOUS_MEAN</th>\n",
              "      <th>BIC_VENOUS_MIN</th>\n",
              "      <th>BIC_VENOUS_MAX</th>\n",
              "      <th>BIC_VENOUS_DIFF</th>\n",
              "      <th>BILLIRUBIN_MEDIAN</th>\n",
              "      <th>BILLIRUBIN_MEAN</th>\n",
              "      <th>...</th>\n",
              "      <th>DIMER_MAX</th>\n",
              "      <th>DIMER_DIFF</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MEAN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MEAN</th>\n",
              "      <th>HEART_RATE_MEAN</th>\n",
              "      <th>RESPIRATORY_RATE_MEAN</th>\n",
              "      <th>TEMPERATURE_MEAN</th>\n",
              "      <th>OXYGEN_SATURATION_MEAN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MEDIAN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MEDIAN</th>\n",
              "      <th>HEART_RATE_MEDIAN</th>\n",
              "      <th>RESPIRATORY_RATE_MEDIAN</th>\n",
              "      <th>TEMPERATURE_MEDIAN</th>\n",
              "      <th>OXYGEN_SATURATION_MEDIAN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MIN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MIN</th>\n",
              "      <th>HEART_RATE_MIN</th>\n",
              "      <th>RESPIRATORY_RATE_MIN</th>\n",
              "      <th>TEMPERATURE_MIN</th>\n",
              "      <th>OXYGEN_SATURATION_MIN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MAX</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MAX</th>\n",
              "      <th>HEART_RATE_MAX</th>\n",
              "      <th>RESPIRATORY_RATE_MAX</th>\n",
              "      <th>TEMPERATURE_MAX</th>\n",
              "      <th>OXYGEN_SATURATION_MAX</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_DIFF</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_DIFF</th>\n",
              "      <th>HEART_RATE_DIFF</th>\n",
              "      <th>RESPIRATORY_RATE_DIFF</th>\n",
              "      <th>TEMPERATURE_DIFF</th>\n",
              "      <th>OXYGEN_SATURATION_DIFF</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_DIFF_REL</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_DIFF_REL</th>\n",
              "      <th>HEART_RATE_DIFF_REL</th>\n",
              "      <th>RESPIRATORY_RATE_DIFF_REL</th>\n",
              "      <th>TEMPERATURE_DIFF_REL</th>\n",
              "      <th>OXYGEN_SATURATION_DIFF_REL</th>\n",
              "      <th>WINDOW</th>\n",
              "      <th>ICU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.994912</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.283019</td>\n",
              "      <td>-0.593220</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.283019</td>\n",
              "      <td>-0.586207</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.237113</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.162393</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>-0.247863</td>\n",
              "      <td>-0.459459</td>\n",
              "      <td>-0.432836</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>-0.420290</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0-2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.994912</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.132075</td>\n",
              "      <td>-0.593220</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.132075</td>\n",
              "      <td>-0.586207</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.443299</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.025641</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.838384</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>-0.459459</td>\n",
              "      <td>-0.313433</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>0.246377</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>2-4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.994912</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.243021</td>\n",
              "      <td>-0.338537</td>\n",
              "      <td>-0.213031</td>\n",
              "      <td>-0.317859</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-0.283951</td>\n",
              "      <td>-0.376923</td>\n",
              "      <td>-0.188679</td>\n",
              "      <td>-0.379310</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-0.340206</td>\n",
              "      <td>-0.4875</td>\n",
              "      <td>-0.572650</td>\n",
              "      <td>-0.857143</td>\n",
              "      <td>0.318681</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>0.286486</td>\n",
              "      <td>0.298507</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>-0.275362</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-0.33913</td>\n",
              "      <td>0.325153</td>\n",
              "      <td>0.114504</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.389967</td>\n",
              "      <td>0.407558</td>\n",
              "      <td>-0.230462</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>4-6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.979069</td>\n",
              "      <td>-0.979069</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.996762</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.243021</td>\n",
              "      <td>-0.338537</td>\n",
              "      <td>-0.213031</td>\n",
              "      <td>-0.317859</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-0.283951</td>\n",
              "      <td>-0.376923</td>\n",
              "      <td>-0.188679</td>\n",
              "      <td>-0.379310</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-0.340206</td>\n",
              "      <td>-0.4875</td>\n",
              "      <td>-0.572650</td>\n",
              "      <td>-0.857143</td>\n",
              "      <td>0.318681</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>0.286486</td>\n",
              "      <td>0.298507</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>-0.275362</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-0.33913</td>\n",
              "      <td>0.325153</td>\n",
              "      <td>0.114504</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.389967</td>\n",
              "      <td>0.407558</td>\n",
              "      <td>-0.230462</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>6-12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.979069</td>\n",
              "      <td>-0.979069</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.996762</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.243021</td>\n",
              "      <td>-0.338537</td>\n",
              "      <td>-0.213031</td>\n",
              "      <td>-0.317859</td>\n",
              "      <td>0.033779</td>\n",
              "      <td>0.665932</td>\n",
              "      <td>-0.283951</td>\n",
              "      <td>-0.376923</td>\n",
              "      <td>-0.188679</td>\n",
              "      <td>-0.379310</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>-0.340206</td>\n",
              "      <td>-0.4875</td>\n",
              "      <td>-0.572650</td>\n",
              "      <td>-0.857143</td>\n",
              "      <td>0.098901</td>\n",
              "      <td>0.797980</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>0.286486</td>\n",
              "      <td>0.298507</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.362319</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>-0.33913</td>\n",
              "      <td>0.325153</td>\n",
              "      <td>0.114504</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>-0.238095</td>\n",
              "      <td>-0.818182</td>\n",
              "      <td>-0.389967</td>\n",
              "      <td>0.407558</td>\n",
              "      <td>-0.230462</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>-0.242282</td>\n",
              "      <td>-0.814433</td>\n",
              "      <td>ABOVE_12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 231 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   PATIENT_VISIT_IDENTIFIER  AGE_ABOVE65  ...    WINDOW  ICU\n",
              "0                         0            1  ...       0-2    0\n",
              "1                         0            1  ...       2-4    0\n",
              "2                         0            1  ...       4-6    0\n",
              "3                         0            1  ...      6-12    0\n",
              "4                         0            1  ...  ABOVE_12    1\n",
              "\n",
              "[5 rows x 231 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxNisY7j2TbZ"
      },
      "source": [
        "Possuímos dados Categóricos em nosso conjunto de dados. Logo, ainda precisamos limpar mais, antes de começarmos a aplicar algum modelo. As colunas `AGE_PERCENTIL`e `WINDOW` possuem informações do tipo **String** que precisam ser categorizadas de forma a não gerar uma discrepância alta de valores e assim influenciar de forma errada nosso modelo. Digo isso pois, a aplicação de um `.astype(\"category\").cat.codes` resultaria em valores iguais a 5,3, 2 e assim em diante, e nossos estão normalizados. Buscando resolver isso, aplico um `pd.get_dummies` para que seja criada uma coluna para cada valor, sendo preenchido de 0s e 1s. Observe também que antes de realizar isso, na linha acima, em `apply`, aplico a função `prepare window`. Ficamos então apenas com o quadro de até duas horas após a admissão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "3xasvoLAwv7P",
        "outputId": "0ede4725-2350-4498-bdc0-8f0fc0aa800a"
      },
      "source": [
        "dados_limpos = dados_limpos.groupby(\"PATIENT_VISIT_IDENTIFIER\").apply(prepare_window)\r\n",
        "dados_limpos = pd.get_dummies(dados_limpos) \r\n",
        "dados_limpos.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>PATIENT_VISIT_IDENTIFIER</th>\n",
              "      <th>AGE_ABOVE65</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>DISEASE GROUPING 1</th>\n",
              "      <th>DISEASE GROUPING 2</th>\n",
              "      <th>DISEASE GROUPING 3</th>\n",
              "      <th>DISEASE GROUPING 4</th>\n",
              "      <th>DISEASE GROUPING 5</th>\n",
              "      <th>DISEASE GROUPING 6</th>\n",
              "      <th>HTN</th>\n",
              "      <th>IMMUNOCOMPROMISED</th>\n",
              "      <th>OTHER</th>\n",
              "      <th>ALBUMIN_MEDIAN</th>\n",
              "      <th>ALBUMIN_MEAN</th>\n",
              "      <th>ALBUMIN_MIN</th>\n",
              "      <th>ALBUMIN_MAX</th>\n",
              "      <th>ALBUMIN_DIFF</th>\n",
              "      <th>BE_ARTERIAL_MEDIAN</th>\n",
              "      <th>BE_ARTERIAL_MEAN</th>\n",
              "      <th>BE_ARTERIAL_MIN</th>\n",
              "      <th>BE_ARTERIAL_MAX</th>\n",
              "      <th>BE_ARTERIAL_DIFF</th>\n",
              "      <th>BE_VENOUS_MEDIAN</th>\n",
              "      <th>BE_VENOUS_MEAN</th>\n",
              "      <th>BE_VENOUS_MIN</th>\n",
              "      <th>BE_VENOUS_MAX</th>\n",
              "      <th>BE_VENOUS_DIFF</th>\n",
              "      <th>BIC_ARTERIAL_MEDIAN</th>\n",
              "      <th>BIC_ARTERIAL_MEAN</th>\n",
              "      <th>BIC_ARTERIAL_MIN</th>\n",
              "      <th>BIC_ARTERIAL_MAX</th>\n",
              "      <th>BIC_ARTERIAL_DIFF</th>\n",
              "      <th>BIC_VENOUS_MEDIAN</th>\n",
              "      <th>BIC_VENOUS_MEAN</th>\n",
              "      <th>BIC_VENOUS_MIN</th>\n",
              "      <th>BIC_VENOUS_MAX</th>\n",
              "      <th>BIC_VENOUS_DIFF</th>\n",
              "      <th>BILLIRUBIN_MEDIAN</th>\n",
              "      <th>BILLIRUBIN_MEAN</th>\n",
              "      <th>BILLIRUBIN_MIN</th>\n",
              "      <th>...</th>\n",
              "      <th>HEART_RATE_MEDIAN</th>\n",
              "      <th>RESPIRATORY_RATE_MEDIAN</th>\n",
              "      <th>TEMPERATURE_MEDIAN</th>\n",
              "      <th>OXYGEN_SATURATION_MEDIAN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MIN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MIN</th>\n",
              "      <th>HEART_RATE_MIN</th>\n",
              "      <th>RESPIRATORY_RATE_MIN</th>\n",
              "      <th>TEMPERATURE_MIN</th>\n",
              "      <th>OXYGEN_SATURATION_MIN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MAX</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MAX</th>\n",
              "      <th>HEART_RATE_MAX</th>\n",
              "      <th>RESPIRATORY_RATE_MAX</th>\n",
              "      <th>TEMPERATURE_MAX</th>\n",
              "      <th>OXYGEN_SATURATION_MAX</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_DIFF</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_DIFF</th>\n",
              "      <th>HEART_RATE_DIFF</th>\n",
              "      <th>RESPIRATORY_RATE_DIFF</th>\n",
              "      <th>TEMPERATURE_DIFF</th>\n",
              "      <th>OXYGEN_SATURATION_DIFF</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_DIFF_REL</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_DIFF_REL</th>\n",
              "      <th>HEART_RATE_DIFF_REL</th>\n",
              "      <th>RESPIRATORY_RATE_DIFF_REL</th>\n",
              "      <th>TEMPERATURE_DIFF_REL</th>\n",
              "      <th>OXYGEN_SATURATION_DIFF_REL</th>\n",
              "      <th>ICU</th>\n",
              "      <th>AGE_PERCENTIL_10th</th>\n",
              "      <th>AGE_PERCENTIL_20th</th>\n",
              "      <th>AGE_PERCENTIL_30th</th>\n",
              "      <th>AGE_PERCENTIL_40th</th>\n",
              "      <th>AGE_PERCENTIL_50th</th>\n",
              "      <th>AGE_PERCENTIL_60th</th>\n",
              "      <th>AGE_PERCENTIL_70th</th>\n",
              "      <th>AGE_PERCENTIL_80th</th>\n",
              "      <th>AGE_PERCENTIL_90th</th>\n",
              "      <th>AGE_PERCENTIL_Above 90th</th>\n",
              "      <th>WINDOW_0-2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PATIENT_VISIT_IDENTIFIER</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.283019</td>\n",
              "      <td>-0.586207</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.237113</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.162393</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>-0.247863</td>\n",
              "      <td>-0.459459</td>\n",
              "      <td>-0.432836</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>-0.420290</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <th>10</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.056604</td>\n",
              "      <td>-0.517241</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>-0.525773</td>\n",
              "      <td>-0.5125</td>\n",
              "      <td>-0.111111</td>\n",
              "      <td>-0.714286</td>\n",
              "      <td>0.604396</td>\n",
              "      <td>0.959596</td>\n",
              "      <td>-0.435897</td>\n",
              "      <td>-0.491892</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.575758</td>\n",
              "      <td>0.101449</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.547826</td>\n",
              "      <td>-0.533742</td>\n",
              "      <td>-0.603053</td>\n",
              "      <td>-0.764706</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.959596</td>\n",
              "      <td>-0.515528</td>\n",
              "      <td>-0.351328</td>\n",
              "      <td>-0.747001</td>\n",
              "      <td>-0.756272</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.961262</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <th>15</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.263158</td>\n",
              "      <td>-0.263158</td>\n",
              "      <td>-0.263158</td>\n",
              "      <td>-0.263158</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.972789</td>\n",
              "      <td>-0.972789</td>\n",
              "      <td>-0.972789</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.528302</td>\n",
              "      <td>-0.448276</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.175258</td>\n",
              "      <td>-0.1125</td>\n",
              "      <td>-0.384615</td>\n",
              "      <td>-0.357143</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>-0.299145</td>\n",
              "      <td>-0.556757</td>\n",
              "      <td>-0.626866</td>\n",
              "      <td>-0.515152</td>\n",
              "      <td>-0.420290</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <th>20</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.935113</td>\n",
              "      <td>-0.935113</td>\n",
              "      <td>-0.935113</td>\n",
              "      <td>...</td>\n",
              "      <td>0.160377</td>\n",
              "      <td>-0.586207</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.868421</td>\n",
              "      <td>0.443299</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.196581</td>\n",
              "      <td>-0.571429</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.939394</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>-0.351351</td>\n",
              "      <td>-0.044776</td>\n",
              "      <td>-0.575758</td>\n",
              "      <td>0.072464</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.877301</td>\n",
              "      <td>-0.923664</td>\n",
              "      <td>-0.882353</td>\n",
              "      <td>-0.952381</td>\n",
              "      <td>-0.979798</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.883669</td>\n",
              "      <td>-0.956805</td>\n",
              "      <td>-0.870968</td>\n",
              "      <td>-0.953536</td>\n",
              "      <td>-0.980333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <th>25</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.537736</td>\n",
              "      <td>-0.517241</td>\n",
              "      <td>-0.196429</td>\n",
              "      <td>0.815789</td>\n",
              "      <td>0.030928</td>\n",
              "      <td>-0.3750</td>\n",
              "      <td>-0.401709</td>\n",
              "      <td>-0.428571</td>\n",
              "      <td>0.252747</td>\n",
              "      <td>0.919192</td>\n",
              "      <td>-0.247863</td>\n",
              "      <td>-0.567568</td>\n",
              "      <td>-0.626866</td>\n",
              "      <td>-0.575758</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.842105</td>\n",
              "      <td>-0.826087</td>\n",
              "      <td>-0.754601</td>\n",
              "      <td>-0.984733</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.976190</td>\n",
              "      <td>-0.979798</td>\n",
              "      <td>-0.860870</td>\n",
              "      <td>-0.714460</td>\n",
              "      <td>-0.986481</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.975891</td>\n",
              "      <td>-0.980129</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 240 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             PATIENT_VISIT_IDENTIFIER  ...  WINDOW_0-2\n",
              "PATIENT_VISIT_IDENTIFIER                               ...            \n",
              "0                        0                          0  ...           1\n",
              "2                        10                         2  ...           1\n",
              "3                        15                         3  ...           1\n",
              "4                        20                         4  ...           1\n",
              "5                        25                         5  ...           1\n",
              "\n",
              "[5 rows x 240 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uibSFIrR3myl"
      },
      "source": [
        "Antes de iniciar a aplicação dos modelos de Machine Learning, vejamos o que temos nos dados agora:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzvtZF6r2JxD",
        "outputId": "bf31fb9b-d0bb-4012-dfe8-10067f48a787"
      },
      "source": [
        "resume_dataframe(dados_limpos)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################ RESUMO BÁSICO ####################\n",
            "\n",
            "Quantidade de instâncias: 352 (linhas)\n",
            "Quantidade de Atributos: 240 (colunas)\n",
            "\n",
            "Não há dados ausentes neste dataset\n",
            "\n",
            "Tipos de  dados que temos :\n",
            "[dtype('uint8'), dtype('float64'), dtype('int64')]\n",
            "\n",
            "##################################################\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om1C3S9bVv7N"
      },
      "source": [
        "Possuimos então 240 colunas no total. Entretanto talvez não seja necessário o uso de todas essas colunas, dado que muitas colunas podem vir a atrapalhar as predições. Criarei dois dataframes, onde ambos buscarão excluir dados com alta correlação, mas onde ambos realizam tal tarefa de forma diferente. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPQIgcFskxH6"
      },
      "source": [
        "### 2 MÉTODOS PARA EXCLUIR DADOS CORRELACIONADOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSA7M1M1ZOq7"
      },
      "source": [
        "**Excluindo-se dados correlacionados com a técnica de Matt Harisson**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bCfmwRPWKzg"
      },
      "source": [
        "#cria-se um dataframe com 3 colunas(duas onde os valores são o nome de colunas e a terceira com os valores de correlação > .95)\r\n",
        "dados_correlacionados = correlated_columns_harrison(dados_limpos,.95)\r\n",
        "\r\n",
        "#filtra-se de ambas as colunas que possuem nomes aqueles que não se repetem, gerando uma lista\r\n",
        "excluir = descartar_colunas_correlacionadas(dados_correlacionados)\r\n",
        "\r\n",
        "#descarta-se as colunas com alta correlação\r\n",
        "dados_limpos_sem_corr_tipo_1 = dados_limpos.drop(excluir,axis=1)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6LMZpdEaCij",
        "outputId": "01896277-fefb-424a-c657-eafd84bc3824"
      },
      "source": [
        "resume_dataframe(dados_limpos_sem_corr_tipo_1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################ RESUMO BÁSICO ####################\n",
            "\n",
            "Quantidade de instâncias: 352 (linhas)\n",
            "Quantidade de Atributos: 64 (colunas)\n",
            "\n",
            "Não há dados ausentes neste dataset\n",
            "\n",
            "Tipos de  dados que temos :\n",
            "[dtype('uint8'), dtype('float64'), dtype('int64')]\n",
            "\n",
            "##################################################\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_W23uZ6ZY-f"
      },
      "source": [
        "**Excluindo-se dados correlacionados com a técnica de Thiago Gonçalves e Alan Spadinni: técnica Gondinni**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvbXhieBWLHd"
      },
      "source": [
        "dados_limpos_sem_corr_tipo_2 = remove_corr_var(dados_limpos)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdYkXqn6aMiD",
        "outputId": "694fca92-3b94-4d36-d56d-4950a0a69906"
      },
      "source": [
        "resume_dataframe(dados_limpos_sem_corr_tipo_2)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################ RESUMO BÁSICO ####################\n",
            "\n",
            "Quantidade de instâncias: 352 (linhas)\n",
            "Quantidade de Atributos: 109 (colunas)\n",
            "\n",
            "Não há dados ausentes neste dataset\n",
            "\n",
            "Tipos de  dados que temos :\n",
            "[dtype('uint8'), dtype('float64'), dtype('int64')]\n",
            "\n",
            "##################################################\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJO-mnLzk4ma"
      },
      "source": [
        "Nota-se que em um método, temos 64 colunas, no outro, 109. \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcMYwa1fjb54"
      },
      "source": [
        "### DADOS A SEREM TREINADOS INICIALMENTE\r\n",
        "\r\n",
        ">Por fim, temos três variáveis referentes aos dados de pacientes:\r\n",
        "\r\n",
        "* `DADOS_LIMPOS` = **POSSUE TODAS AS COLUNAS (240)**\r\n",
        "* `DADOS_LIMPOS_SEM_CORR_TIPO_1` = **POSSUE COLUNAS SEM ALTA CORRELAÇÃO COM BASE NA TÉCNICA DE MATT HARISSON (64)**\r\n",
        "* `DADOS_LIMPOS_SEM_CORR_TIPO_2` = **POSSUE COLUNAS SEM ALTA CORRELAÇÃO COM BASE NA TÉCNICA GONDINNI (109)**\r\n",
        "\r\n",
        ">Todas as variáveis estão sem dados Not a Number (NaN) e serão usadas em todos os modelos para que possamos ver qual se desempenhará melhor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyYgpUub4SM0"
      },
      "source": [
        "# IMPLEMENTAÇÃO DE MODELOS DE APRENDIZAGEM DE MÁQUINA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10c84J__kbrm"
      },
      "source": [
        "Nosso projeto consiste na classificação de pacientes que devem ir para UTI ou não, com base em uma série de dados referentes a seus exames e sinais vitais. Para isso, nada melhor do que aplicar técnicas de aprendizagem de máquinas voltadas para classificação. Por conceito temos:\r\n",
        "\r\n",
        ">Os modelos de ML para problemas de classificação binária preveem um resultado binário (uma de duas classes possíveis).<br> ([link para referência](https://docs.aws.amazon.com/pt_br/machine-learning/latest/dg/types-of-ml-models.html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yakxcXyDugdp"
      },
      "source": [
        "No nosso caso, utilizarei os seguintes modelos:\r\n",
        "\r\n",
        "* DummyClassifier\r\n",
        "* LogisticRegression\r\n",
        "* DecisionTreeClassifier\r\n",
        "* KNeighborsClassifier\r\n",
        "* GaussianNB\r\n",
        "* SVC\r\n",
        "* RandomForestClassifier\r\n",
        "* XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXsjbe6eun3W"
      },
      "source": [
        "Contudo, apesar de uma breve explicação sobre cada um, não trabalharemos com todos. Iremos apenas inicialmente rodá-los e dependendo do desempenho, ficaremos com 4 ou 5 modelos para trabalhar. Logo, algumas coisas a se levar em conta:\r\n",
        "\r\n",
        "* Sua precisão, recall e acucácia;\r\n",
        "* Para que o modelo possa ser usado, ele deve possuir um custo-benefício bom o suficiente para entrar em produção. De nada serve um modelo 100% bom em classificar, mas que leva 2 horas para fazer isso (levando em conta que os dados crescerão com o tempo).\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfMElasuH2yc"
      },
      "source": [
        "Testando inicialmente os conjunto de dados com os modelos, mas sem especificar os parâmetros, temos:<br>\r\n",
        "***\r\n",
        "***\r\n",
        "**OBSERVAÇÃO**: desconsiderar avisos de warning\r\n",
        "***\r\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHsMqXyl-IBd"
      },
      "source": [
        "Rodando primeiramente para `dados_limpos`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0v768JFDCjB",
        "outputId": "2c908be1-8da1-4062-f92f-77039283a63e"
      },
      "source": [
        "resultados_dados_limpos = rodar_varios_modelos(dados_limpos)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpDtIJj9-U9J"
      },
      "source": [
        "Rodando para `dados_limpos_sem_corr_tipo_1`\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DD1JpRo61Ff",
        "outputId": "1c038b56-b489-40b0-91ab-099ef2f604c2"
      },
      "source": [
        "resultados_sem_corr_tipo_1 = rodar_varios_modelos(dados_limpos_sem_corr_tipo_1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXlSm_0O-acw"
      },
      "source": [
        "rodando em `dados_limpos_sem_corr_tipo_2`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhzm-qb57RSu",
        "outputId": "030665d2-6d76-476d-a73e-15c8fcb0b11f"
      },
      "source": [
        "resultados_sem_corr_tipo_2 =rodar_varios_modelos(dados_limpos_sem_corr_tipo_2)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csD5JFJ7-06n"
      },
      "source": [
        "#### Resultados iniciais para vários modelos e quais serão usados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6RE4aQVDFSF"
      },
      "source": [
        "# EXPLICAR PARÂMETROS AUC STD E TEMPO DE EXECUÇÃO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P764fXSqCO6u"
      },
      "source": [
        "Abaixo, iremos conferir melhor a questão de desempenho dos modelos que foram treinados. Todos eles servem para classificação, contudo, podem não ser o melhor para o que é proposto no nosso projeto. Tendo isso em mente, algumas métricas iniciais são levadas em conta e que podem fazer a diferença.\r\n",
        "<br>\r\n",
        "O AUC - Area Under Curve ou área sobre a curva, mede a capacidade do modelo de prever uma pontuação maior de exemplos positivos em comparação com os exemplos negativos. Como ela não depende do corte da pontuação, você poderá ter uma ideia da precisão da previsão do modelo a partir da métrica AUC, sem escolher um limite.\r\n",
        "<br>\r\n",
        "Já o STD ou o desvio padrão é uma medida que indica a dispersão dos dados dentro de uma amostra com relação à média. Assim, quando se calcula o desvio padrão juntamente com a média de diferentes grupos, obtém-se mais informações para avaliar e diferenciar seus comportamentos.\r\n",
        "<br>\r\n",
        "Por fim, o tempo de execução servirá para termos uma noção de quanto tempo está sendo levado para divisão de dados, treino, predição e teste em cada modelo. Isso é de fundamental importância e será determinante mais pra frente, quando nossa base de dados se tornar maior e mais complexa. Afinal, do que adianta um modelo 100% preciso, mas que demora inúmeras horas para auxiliar em algo tão emergencial como saber se um paciente necessita ou não de UTI?\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-DWcVta-5lY"
      },
      "source": [
        "Vejamos então como o filtro de dados realizados, auxiliarão no resultado final dos modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaXAqSlY_IVg",
        "outputId": "9ef3de44-09f7-49a5-c5a6-12e8e98e8cf0"
      },
      "source": [
        "resultados_dados_limpos"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DummyClassifier        AUC:                0.502 STD: 0.06     Tempo execução: 0.02911972999572754 seconds',\n",
              " 'LogisticRegression     AUC:                0.740 STD: 0.03     Tempo execução: 0.36710309982299805 seconds',\n",
              " 'DecisionTreeClassifier AUC:                0.619 STD: 0.03     Tempo execução: 0.1636958122253418 seconds',\n",
              " 'KNeighborsClassifier   AUC:                0.655 STD: 0.06     Tempo execução: 0.11810517311096191 seconds',\n",
              " 'GaussianNB             AUC:                0.744 STD: 0.03     Tempo execução: 0.03795027732849121 seconds',\n",
              " 'SVC                    AUC:                0.769 STD: 0.08     Tempo execução: 0.2043297290802002 seconds',\n",
              " 'RandomForestClassifier AUC:                0.788 STD: 0.01     Tempo execução: 1.117182731628418 seconds',\n",
              " 'XGBClassifier          AUC:                0.779 STD: 0.02     Tempo execução: 1.270688533782959 seconds']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4X6Xhxn81pA",
        "outputId": "7335c224-ea73-46fe-ca76-ba625175baf8"
      },
      "source": [
        "resultados_sem_corr_tipo_1"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DummyClassifier        AUC:                0.502 STD: 0.06     Tempo execução: 0.025545597076416016 seconds',\n",
              " 'LogisticRegression     AUC:                0.712 STD: 0.09     Tempo execução: 0.19325542449951172 seconds',\n",
              " 'DecisionTreeClassifier AUC:                0.589 STD: 0.03     Tempo execução: 0.04266762733459473 seconds',\n",
              " 'KNeighborsClassifier   AUC:                0.670 STD: 0.04     Tempo execução: 0.06586146354675293 seconds',\n",
              " 'GaussianNB             AUC:                0.690 STD: 0.04     Tempo execução: 0.026978731155395508 seconds',\n",
              " 'SVC                    AUC:                0.694 STD: 0.06     Tempo execução: 0.08562803268432617 seconds',\n",
              " 'RandomForestClassifier AUC:                0.682 STD: 0.05     Tempo execução: 0.81573486328125 seconds',\n",
              " 'XGBClassifier          AUC:                0.731 STD: 0.04     Tempo execução: 0.3091394901275635 seconds']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc8i1VF8_EDM",
        "outputId": "86119b0b-3277-4dce-e010-97bd79b4d680"
      },
      "source": [
        "resultados_sem_corr_tipo_2"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DummyClassifier        AUC:                0.502 STD: 0.06     Tempo execução: 0.03227996826171875 seconds',\n",
              " 'LogisticRegression     AUC:                0.750 STD: 0.04     Tempo execução: 0.24123048782348633 seconds',\n",
              " 'DecisionTreeClassifier AUC:                0.611 STD: 0.02     Tempo execução: 0.08976912498474121 seconds',\n",
              " 'KNeighborsClassifier   AUC:                0.698 STD: 0.06     Tempo execução: 0.06900429725646973 seconds',\n",
              " 'GaussianNB             AUC:                0.731 STD: 0.03     Tempo execução: 0.028427600860595703 seconds',\n",
              " 'SVC                    AUC:                0.754 STD: 0.09     Tempo execução: 0.11909842491149902 seconds',\n",
              " 'RandomForestClassifier AUC:                0.793 STD: 0.03     Tempo execução: 0.9046792984008789 seconds',\n",
              " 'XGBClassifier          AUC:                0.776 STD: 0.02     Tempo execução: 0.5851531028747559 seconds']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Enq_I1B2_m-t"
      },
      "source": [
        "Ao que tudo indica, os modelos performaram melhor em:\r\n",
        "* `dados_limpos` (onde permaneceram a maior parte das colunas)\r\n",
        "* `dados_limpos_sem_corr_tipo_2` (Segundo o método GONDINNI)\r\n",
        "\r\n",
        "Além disso, no geral, os modelos que obtiveram bons resultados :\r\n",
        "* Logistic Regression\r\n",
        "* GaussianNB\r\n",
        "* SVC\r\n",
        "* Random Forest Classifier\r\n",
        "* XGBClassifier\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIBV6fevCZWj"
      },
      "source": [
        "Portanto, analisaremos estes modelos mais a fundo, apresentando uma breve explicação a cerca de seu funcionamento, e realizaremos alguns testes referentes a acerto, tempo de execução e processamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXDZc9fsDQL5"
      },
      "source": [
        "# 📊📖 EXPLICANDO MODELOS ESCOLHIDOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t_5DTq_DUYT"
      },
      "source": [
        "Dado os modelos escolhidos, explicarei inicialmente um pouco de cada um, buscando não extender demais o tema para não perdermos o foco. Logo depois, iremos escolher quais resolvem melhor nosso problema, testar com tais modelos e determinar quais se saíram melhores, para no final, decidirmos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fimvRg2TDT_J"
      },
      "source": [
        "## 📕 Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joyzYRCqKw8e"
      },
      "source": [
        "Antes de explicar a **logistic regression** ou **regressão logistica**, é necessário compreender um pouco sobre regressão Linear. A **regressão Linear** é o processo de traçar uma reta através dos dados que são gerados através de um diagrama de dispersão. A partir daí, buscamos traçar uma equação que gere uma reta que nos mostre a relação existente nos dados.<br>\r\n",
        "A equação usada para buscar tal reta é :\r\n",
        "\\begin{equation}\r\n",
        "\\hat y = \\alpha + \\beta x + e\r\n",
        "\\end{equation}\r\n",
        "\r\n",
        "onde:\r\n",
        "* **x** : Variável independente que busca explicar y\r\n",
        "* **y**: Variável dependente a ser prevista\r\n",
        "* $\\alpha$ e $\\beta$ : são parâmetros de distribuição\r\n",
        "* $e$ : erros de medida\r\n",
        "\r\n",
        "Abaixo, temos um exemplo de regressão linear. Os pontos em vermelho representam nossos dados dispersos ao longo de um plano cartesiano em $R^2$ e em azul, temos uma reta que é gerada a partir de uma função que nós criamos derivada da equação de regressão linear.\r\n",
        "\r\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/LinearRegression.svg/1200px-LinearRegression.svg.png\" width=480>\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onVdMJQlRHB8"
      },
      "source": [
        "Assim, supondo que nosso objetivo fosse, a partir de uma base de dados, classificar a qualidade dos estudos de alunos de acordo com as horas de estudo e suas respectivas notas, poderiamos aplicar a regressão linear facilmente e assim buscar a probabilidade do aluno tirar uma nota $y$ baseado nas $x$ horas que ficou estudando."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLvmb1eQRi1k"
      },
      "source": [
        "Contudo, e se buscássemos saber qual a probabilidade de uma pessoa comprar um produto. Nossa variável resposta seria *comprar* e *não-comprar*. Com base em algumas variáveis como idade, salario e afins, como poderiamos classificar as pessoas que comprariam ou não o nosso produto, ou no caso do projeto, quais irão ou não precisar de UTI. Esse é um caso em que a regressão linear não nos ajudaria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4Bsx94nUoDK"
      },
      "source": [
        "Nesse caso, podemos então, aplicar uma regressão logistica, que apesar do nome, é na verdade um modelo linear de classificação. Neste modelo, as probabilidades que descrevem os possíveis resultados de um único ensaio são modeladas com o auxílio de uma função logística.<br>\r\n",
        "Equação da função logística:\r\n",
        "\\begin{equation}\r\n",
        "  f(x)={\\frac {L}{1+e^{-k(x-x_{0})}}}\\end{equation}\r\n",
        "\r\n",
        "onde:\r\n",
        "* $x_0$: valor do ponto médio do sigmoide;\r\n",
        "* $L$ : valor máximo da curva;\r\n",
        "* $K$: a taxa de crescimento logístico ou a inclinação da curva.\r\n",
        "\r\n",
        "Visualmente a função logística é assim:<br>\r\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIFuas0fXtTk"
      },
      "source": [
        "A regressão logística é um recurso que nos permite estimar\r\n",
        "a probabilidade associada à ocorrência de determinado\r\n",
        "evento em face de um conjunto de variáveis explanatórias.\r\n",
        "Como característica, Busca estimar a probabilidade da variável\r\n",
        "dependente assumir um determinado valor em\r\n",
        "função dos conhecidos de outras variáveis e os resultados da análise ficam contidos no\r\n",
        "intervalo de zero a um.\r\n",
        "<br>\r\n",
        "Na regressão logística, a probabilidade de ocorrência de um\r\n",
        "evento pode ser estimada diretamente. No caso da variável\r\n",
        "dependente\r\n",
        "Y assumir apenas dois possíveis estados (1 ou 0)\r\n",
        "e\r\n",
        "haver um conjunto de\r\n",
        "p variáveis independentes\r\n",
        "X1 , X2 , ... , Xp\r\n",
        ", o\r\n",
        "modelo de regressão logística pode ser escrito da seguinte forma:\r\n",
        "\r\n",
        "\\begin{equation}\r\n",
        "P\\big(Y = 1 ) = \\frac{1}{1 + e^{-g(x)}}\r\n",
        "\\end{equation}\r\n",
        "\r\n",
        "onde: \r\n",
        "\\begin{equation}\r\n",
        "g\\big(x\\big) = B_0 + B_1X_1 + ... B_pX_p\r\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqKcJ69mawLM"
      },
      "source": [
        "Abaixo temos um exemplo mostrando a dirença entre regressão linear e regressão logística:\r\n",
        "\r\n",
        "<img src= \"https://estatsite.com.br/wp-content/uploads/2018/08/1-3.jpg\" width=690>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvddOkDNbX8a"
      },
      "source": [
        "Os pontos brancos em y=1 e y=0 podem ser interpretados como comprar e não-comprar, ou no nosso caso, precisa de UTI = 0, não precisa de UTI = 1. Veja como  a regressão logistica irá conseguir pegar um maior conjunto de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDNKWvHbcATq"
      },
      "source": [
        "## 📕 GaussianNB\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2uwHDqicraa"
      },
      "source": [
        "Implementa o algoritmo **Gaussian Naive Bayes** para classificação. Os métodos são baseados na aplicação do teorema de Bayes com a suposição \"ingênua\" de independência condicional entre cada par de características dado o valor da variável classe. O teorema de Bayes afirma a seguinte relação, dada a variável de classe e vetor de características dependentes através de $yx_1x_n$.\r\n",
        "\r\n",
        "\\begin{equation}\r\n",
        "P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) P(x_1, \\dots, x_n \\mid y)}\r\n",
        "                                 {P(x_1, \\dots, x_n)}\r\n",
        "\\end{equation}\r\n",
        "\r\n",
        "Baseado no “Teorema de Bayes”, o modelo foi criado por um matemático inglês, e também ministro presibiteriano, chamado Thomas Bayes (1701 – 1761) para tentar provar a existência de Deus.\r\n",
        "<br>\r\n",
        "Ele recebe o nome de “naive” (ingênuo) porque desconsidera a correlação entre as variáveis (features). Ou seja, se determinada fruta é rotulada como “Limão”, caso ela também seja descrita como “Verde” e “Redonda”, o algoritmo não vai levar em consideração a correlação entre esses fatores. Isso porque trata cada um de forma independente.<br>\r\n",
        "Entre as possibilidades de aplicações está a classificação de um e-mail como SPAM ou Não-SPAM e a identificação de um assunto com base em seu conteúdo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3oLp4gVf7bq"
      },
      "source": [
        "Segundo a documentação do **Sklearn**:\r\n",
        "> *Apesar de suas suposições aparentemente super simplificadas, os classificadores ingênuos de Bayes têm funcionado muito bem em muitas situações do mundo real, famosamente classificação de documentos e filtragem de spam. Eles requerem uma pequena quantidade de dados de treinamento para estimar os parâmetros necessários. [...] Embora  seja conhecido como um classificador decente, é conhecido por ser um estimador ruim, de modo que as saídas de probabilidade não devem ser levadas muito a sério.*\r\n",
        "\r\n",
        "Imagem de exemplo de seu comportamento:\r\n",
        "\r\n",
        "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_calibration_thumb.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlcNTKnFhBBa"
      },
      "source": [
        "## 📕 SVC - Support Vector Classification ou  Classificação vetorial de suporte.\r\n",
        "\r\n",
        "O **SVC**  é uma implementação diferente do mesmo algoritmo, **SVM** (Support Vector Machines ou máquinas vetoriais de suporte) que são  um conjunto de métodos de aprendizagem supervisionados utilizados para classificação, regressão e detecção de outliers. O SVM tem como vantagem:\r\n",
        " * Ser eficaz em espaços de alta dimensão;\r\n",
        " * Ainda eficaz nos casos em que o número de dimensões é maior do que o número de amostras.\r\n",
        "\r\n",
        "O SVM é definido como:\r\n",
        ">*é um algoritmo que busca uma linha de separação entre duas classes distintas analisando os dois pontos, um de cada grupo, mais próximos da outra classe. Isto é, o SVM escolhe a reta — também chamada de hiperplano em maiores dimensões— entre dois grupos que se distancia mais de cada um (no caso abaixo, a reta vermelha).*\r\n",
        "\r\n",
        "<img src=\"https://miro.medium.com/max/563/1*DW6xRZ9ylA3JMnlfNFuuBg.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGqTc21qhS5M"
      },
      "source": [
        "Os modelos SVM irão tentar encontrar uma separação linear entre as amostras do conjunto de dados.\r\n",
        "Um exemplo visual:\r\n",
        "<img src=\"https://www.machinecurve.com/wp-content/uploads/2020/05/dataset.png\" >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZg6XjHGpTqi"
      },
      "source": [
        "## 📕 Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NqP9qNQpXna"
      },
      "source": [
        "Random Forest ou Florestas aleatórias, é um algoritmo de aprendizagem supervisionado. Pode ser usado tanto para classificação quanto para regressão. É também o algoritmo mais flexível e fácil de usar. Uma floresta é composta por árvores. Diz-se que quanto mais árvores ela tem, mais robusta é uma floresta. Florestas aleatórias criam árvores de decisão em amostras de dados selecionadas aleatoriamente, obtém previsão de cada árvore e seleciona a melhor solução por meio de votação. Ele também fornece um indicador muito bom da importância do recurso. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehl5HMOTpXqR"
      },
      "source": [
        "Como vantagens temos:\r\n",
        "\r\n",
        "* Florestas aleatórias são consideradas como um método altamente preciso e robusto devido ao número de árvores de decisão que participam do processo.\r\n",
        "* Não sofre do problema de excesso de adaptação. A principal razão é que leva a média de todas as previsões, o que cancela os vieses.\r\n",
        "* O algoritmo pode ser usado tanto em problemas de classificação quanto de regressão.\r\n",
        "* Florestas aleatórias também podem lidar com valores perdidos. Existem duas maneiras de lidar com isso: usar valores medianos para substituir variáveis contínuas e calcular a média ponderada de proximidade dos valores perdidos.\r\n",
        "* Você pode obter a importância relativa do recurso, o que ajuda na seleção dos recursos mais contribuintes para o classificador.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx_LdkjQ4xXG"
      },
      "source": [
        "Podemos ainda plotar uma arvore para ter uma noção de como ocorre a distribuição:\r\n",
        "\r\n",
        "<img src=\"https://shiring.github.io/machine_learning/2017/03/16/rf_plot_ggraph_files/figure-markdown_github/unnamed-chunk-4-1.png\" width=800>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBnd5CME9Wvf"
      },
      "source": [
        "## 📕 XGBoost Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvx2oGnh9yK-"
      },
      "source": [
        "XGBoost é uma biblioteca de aumento de gradiente distribuído otimizada projetada para ser altamente eficiente, flexível e portátil. Ele implementa algoritmos de aprendizagem de máquina sob a estrutura Gradient Boosting. O XGBoost fornece um reforço paralelo de árvores (também conhecido como GBDT, GBM) que resolvem muitos problemas de ciência de dados de forma rápida e precisa. <br>\r\n",
        "O mesmo código é executado nos principais ambientes distribuídos (Hadoop, SGE, MPI) e pode resolver problemas além de bilhões de exemplos.\r\n",
        "<Br>\r\n",
        "Podemos ainda visualizar como ocorre o comportamento dos nossos dados estão sendo usados:<br>\r\n",
        "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/07/XGBoost-Plot-of-Single-Decision-Tree-Left-To-Right.png\" width=590>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTm5MivkAel_"
      },
      "source": [
        "Para um maior conhecimento técnico sobre a biblioteca, com as explicações matemáticas aprofundadas feitas pelos próprios autores, consulte o [documento oficial](https://arxiv.org/pdf/1603.02754.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B67rtq8LBrpu"
      },
      "source": [
        "# TESTANDO OS MODELOS INDIVIDUALMENTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6tcJ2mGE7h-"
      },
      "source": [
        "Chegou o momento de testarmos individualmente cada modelo, aplicando parâmetros específicos e buscando extrair o máximo que der de cada um, com o objetivo de aumentar os acertos, usando as duas base de dados:\r\n",
        "* `dados_limpos`\r\n",
        "* `dados_limpos_sem_corr_tipo_2` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIr5W0AOEdyO"
      },
      "source": [
        "## LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enAzLB1tEd00"
      },
      "source": [
        "## GAUSSIANNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1edSmbglEd3V"
      },
      "source": [
        "## SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRN-ASwqEd6N"
      },
      "source": [
        "## RANDOM FOREST CLASSIFIER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVEFfOEmEzxe"
      },
      "source": [
        "## XGBOOST CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF_A-Yv8fQfp"
      },
      "source": [
        ""
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6sAKq9HYGPb"
      },
      "source": [
        "#REFERÊNCIAS\r\n",
        "\r\n",
        "[Sklearn - Modelos Lineares](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)\r\n",
        "\r\n",
        "[Regressão Logística - Prof. Adriana Silva](https://www.youtube.com/watch?v=dcsZsA_wipE&ab_channel=EstaTiDados)\r\n",
        "\r\n",
        "[Modelos de Predição | Regressão Logística](https://medium.com/turing-talks/turing-talks-14-modelo-de-predi%C3%A7%C3%A3o-regress%C3%A3o-log%C3%ADstica-7b70a9098e43)\r\n",
        "[edisciplinas - usp](https://edisciplinas.usp.br/pluginfile.php/3769787/mod_resource/content/1/09_RegressaoLogistica.pdf)\r\n",
        "\r\n",
        "[Sklearn - 1.9 Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes)\r\n",
        "\r\n",
        "[Data Geeks - Classificação com Naive Bayes](https://www.datageeks.com.br/naive-bayes/)\r\n",
        "\r\n",
        "\r\n",
        "[Modelos de Predição| SVM](https://medium.com/turing-talks/turing-talks-12-classifica%C3%A7%C3%A3o-por-svm-f4598094a3f1)\r\n",
        "\r\n",
        "[Creating a simple binary SVM classifier with python and Scikit-learn](https://www.machinecurve.com/index.php/2020/05/03/creating-a-simple-binary-svm-classifier-with-python-and-scikit-learn/#choosing-a-kernel-function)\r\n",
        "\r\n",
        "\r\n",
        "[Entendendo classificadores de florestas aleatórias em Python](https://www.datacamp.com/community/tutorials/random-forests-classifier-python)\r\n",
        "\r\n",
        "[XGBoost: A Scalable Tree Boosting System](https://arxiv.org/pdf/1603.02754.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgElb37BfMPG"
      },
      "source": [
        ""
      ],
      "execution_count": 49,
      "outputs": []
    }
  ]
}