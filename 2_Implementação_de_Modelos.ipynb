{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 - Implementação de Modelos",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgHxFgPMfSNfHfNtugbJEz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatheusOrange211/Sirio_Libanes_ICU_Prediction/blob/main/2_Implementa%C3%A7%C3%A3o_de_Modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moJexAm3sVx5"
      },
      "source": [
        "Este trabalho foi desenvolvido por **Matheus Naranjo Corrêa**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qvYXf2kg6wS"
      },
      "source": [
        "# TESTANDO MODELOS PARA PREDIÇÃO DE PACIENTES QUE PRECISARÃO DE UTI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MmOw1xpj6sy"
      },
      "source": [
        "Conforme solicitado pela direção do Hospital Sírio Libanês ao departamento de Tecnologia e Dados, apresentaremos abaixo uma proposta de solução para o seguinte problema:\r\n",
        "\r\n",
        "**PROBLEMA**\r\n",
        "> A pandemia da SARS-COVID-19 (popularmente conhecido como coronavírus), vem causando grandes estresses nos sistemas de saúdes globais. Países com alta taxa de desenvolvimento vêm sofrendo com a falta de leitos de Unidade de Terapia Intensiva (UTI) na internação de seus pacientes, levando equipes médicas a terem que aplicar métodos de escolha severos, dando prioridade para os mais idosos e graves. Contudo, tais métodos não auxiliam na resolução do problema dado a alta taxa de contaminação existente, consequência das ondas de infecção que vêm sendo causadas em um efeito de *onda* ao redor do mundo. <br>\r\n",
        "Tal problema afeta também países emergentes e subdesenvolvidos, que geralmente já possuem sistemas de saúde superlotados, como no caso do Brasil. Infelizmente a superlotação e a falta de leitos já sobrecarregou sistemas de vários estados, como no caso do estado do Amazonas ([link da matéria](https://g1.globo.com/am/amazonas/noticia/2021/01/14/secretario-de-saude-do-am-fala-que-estado-vive-colapso-do-plano-logistico.ghtml)), onde pacientes não estão mais conseguindo acesso a UTI, assim como não possuem equipamentos básicos para a manutenção de vida, como oxigênio. <br>\r\n",
        "Com base nesses acontecimentos e até mesmo na prevenção de sobrecarga do sistema de saúde das redes privadas, o Hospital Sírio-Libanês, referência internacional em saúde, busca prevenir e até mesmo predizer, com base em dados clínicos de seus pacientes, conforme forem sendo admitidos no ambiente hospitalar, a necessidade ou não de internação nas UTIs nas próximas horas. A ideia por trás disso é conseguir desenvolver um modelo de aprendizagem de máquina, conhecido com **Machine Learning**, que consiga auxiliar a junta médica a tomar decisões referentes a necessidade ou não de internação na UTI para aquele paciente, usando as boas práticas de programação e respeitando a Lei Geral da Proteção de dados, conforme indica a lei federal Lei nº 13.709/2018."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktORiHxApnG-"
      },
      "source": [
        "Conforme analisado no notebook [Visualizando os Dados](https://github.com/MatheusOrange211/Sirio_Libanes_ICU_Prediction/blob/main/Visualizando_os_dados_Sirio_Libanes.ipynb), realizamos uma breve exploração acerca dos dados fornecidos pela equipe de pesquisa do hospital, buscando entender o que fora nos enviado e como deveriamos ir trabalhando com os dados. Ficou decidido, com base em análises (figura 4 - Internação em UTI pelo tempo de Admissão: Precisou de UTI?), que o melhor janela de admissão para se trabalhar era de até duas horas, uma vez que com ela, poderiamos tentar predizer mais cedo se o paciente necessitaria ou não de internação na UTI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QwVkvFLrZkz"
      },
      "source": [
        "Nessa segunda parte do projeto, optaremos por testar modelos de Machine Learning que ajudem no nosso problema de **classificação**. Inicialmente realizaremos a importação dos dados, sua limpeza (com funções criadas no notebook de visualização de dados e outras), separação dos dados para treino e teste, o treinamento com alguns algoritmos de classificação e por fim sua validação e implementação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oruTNNjEsPAB"
      },
      "source": [
        "# IMPORTANDO BIBLIOTECAS\r\n",
        "\r\n",
        "Importaremos as bibliotecas básicas usadas no desenvolvimento de análises e tratamento de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZKnzoD1gkhB"
      },
      "source": [
        "#Bibliotecas básicas para análises e visualização de dados\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "#---------------------------------------------------------\r\n",
        "#biblioteca para medição de tempo de execuções dos modelos\r\n",
        "import time \r\n",
        "#---------------------------------------------------------\r\n",
        "#biblioteca de Modelos de Machine Learning e ferramentas de auxilio\r\n",
        "#---------------------------------------------------------\r\n",
        "from sklearn import model_selection\r\n",
        "from sklearn.dummy import DummyClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from xgboost import XGBClassifier\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmG2AGYTs2Mh"
      },
      "source": [
        "# Dados\r\n",
        "\r\n",
        "Os dados fornecidos pela equipe de pesquisa do Hospital Sírio Libanês estão disponíves neste site: [Kaggle - Sírio-libanês](https://www.kaggle.com/S%C3%ADrio-Libanes/covid19). Uma explicação dos dados já fora feita no notebook anterior, logo, passaremos para outra parte.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "GptmTliGsnpk",
        "outputId": "ee5dc4f6-4598-41ce-a502-b79297ea6b74"
      },
      "source": [
        "dados = pd.read_excel(\"https://github.com/alura-cursos/covid-19-clinical/blob/main/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx?raw=true\")\r\n",
        "dados.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PATIENT_VISIT_IDENTIFIER</th>\n",
              "      <th>AGE_ABOVE65</th>\n",
              "      <th>AGE_PERCENTIL</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>DISEASE GROUPING 1</th>\n",
              "      <th>DISEASE GROUPING 2</th>\n",
              "      <th>DISEASE GROUPING 3</th>\n",
              "      <th>DISEASE GROUPING 4</th>\n",
              "      <th>DISEASE GROUPING 5</th>\n",
              "      <th>DISEASE GROUPING 6</th>\n",
              "      <th>HTN</th>\n",
              "      <th>IMMUNOCOMPROMISED</th>\n",
              "      <th>OTHER</th>\n",
              "      <th>ALBUMIN_MEDIAN</th>\n",
              "      <th>ALBUMIN_MEAN</th>\n",
              "      <th>ALBUMIN_MIN</th>\n",
              "      <th>ALBUMIN_MAX</th>\n",
              "      <th>ALBUMIN_DIFF</th>\n",
              "      <th>BE_ARTERIAL_MEDIAN</th>\n",
              "      <th>BE_ARTERIAL_MEAN</th>\n",
              "      <th>BE_ARTERIAL_MIN</th>\n",
              "      <th>BE_ARTERIAL_MAX</th>\n",
              "      <th>BE_ARTERIAL_DIFF</th>\n",
              "      <th>BE_VENOUS_MEDIAN</th>\n",
              "      <th>BE_VENOUS_MEAN</th>\n",
              "      <th>BE_VENOUS_MIN</th>\n",
              "      <th>BE_VENOUS_MAX</th>\n",
              "      <th>BE_VENOUS_DIFF</th>\n",
              "      <th>BIC_ARTERIAL_MEDIAN</th>\n",
              "      <th>BIC_ARTERIAL_MEAN</th>\n",
              "      <th>BIC_ARTERIAL_MIN</th>\n",
              "      <th>BIC_ARTERIAL_MAX</th>\n",
              "      <th>BIC_ARTERIAL_DIFF</th>\n",
              "      <th>BIC_VENOUS_MEDIAN</th>\n",
              "      <th>BIC_VENOUS_MEAN</th>\n",
              "      <th>BIC_VENOUS_MIN</th>\n",
              "      <th>BIC_VENOUS_MAX</th>\n",
              "      <th>BIC_VENOUS_DIFF</th>\n",
              "      <th>BILLIRUBIN_MEDIAN</th>\n",
              "      <th>BILLIRUBIN_MEAN</th>\n",
              "      <th>...</th>\n",
              "      <th>DIMER_MAX</th>\n",
              "      <th>DIMER_DIFF</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MEAN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MEAN</th>\n",
              "      <th>HEART_RATE_MEAN</th>\n",
              "      <th>RESPIRATORY_RATE_MEAN</th>\n",
              "      <th>TEMPERATURE_MEAN</th>\n",
              "      <th>OXYGEN_SATURATION_MEAN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MEDIAN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MEDIAN</th>\n",
              "      <th>HEART_RATE_MEDIAN</th>\n",
              "      <th>RESPIRATORY_RATE_MEDIAN</th>\n",
              "      <th>TEMPERATURE_MEDIAN</th>\n",
              "      <th>OXYGEN_SATURATION_MEDIAN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MIN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MIN</th>\n",
              "      <th>HEART_RATE_MIN</th>\n",
              "      <th>RESPIRATORY_RATE_MIN</th>\n",
              "      <th>TEMPERATURE_MIN</th>\n",
              "      <th>OXYGEN_SATURATION_MIN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MAX</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MAX</th>\n",
              "      <th>HEART_RATE_MAX</th>\n",
              "      <th>RESPIRATORY_RATE_MAX</th>\n",
              "      <th>TEMPERATURE_MAX</th>\n",
              "      <th>OXYGEN_SATURATION_MAX</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_DIFF</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_DIFF</th>\n",
              "      <th>HEART_RATE_DIFF</th>\n",
              "      <th>RESPIRATORY_RATE_DIFF</th>\n",
              "      <th>TEMPERATURE_DIFF</th>\n",
              "      <th>OXYGEN_SATURATION_DIFF</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_DIFF_REL</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_DIFF_REL</th>\n",
              "      <th>HEART_RATE_DIFF_REL</th>\n",
              "      <th>RESPIRATORY_RATE_DIFF_REL</th>\n",
              "      <th>TEMPERATURE_DIFF_REL</th>\n",
              "      <th>OXYGEN_SATURATION_DIFF_REL</th>\n",
              "      <th>WINDOW</th>\n",
              "      <th>ICU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.283019</td>\n",
              "      <td>-0.593220</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.283019</td>\n",
              "      <td>-0.586207</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.237113</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.162393</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>-0.247863</td>\n",
              "      <td>-0.459459</td>\n",
              "      <td>-0.432836</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>-0.420290</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0-2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.132075</td>\n",
              "      <td>-0.593220</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.132075</td>\n",
              "      <td>-0.586207</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.443299</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.025641</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.838384</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>-0.459459</td>\n",
              "      <td>-0.313433</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>0.246377</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>2-4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.994912</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4-6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.318681</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.275362</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>6-12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.979069</td>\n",
              "      <td>-0.979069</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.996762</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.243021</td>\n",
              "      <td>-0.338537</td>\n",
              "      <td>-0.213031</td>\n",
              "      <td>-0.317859</td>\n",
              "      <td>0.033779</td>\n",
              "      <td>0.665932</td>\n",
              "      <td>-0.283951</td>\n",
              "      <td>-0.376923</td>\n",
              "      <td>-0.188679</td>\n",
              "      <td>-0.379310</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>-0.340206</td>\n",
              "      <td>-0.4875</td>\n",
              "      <td>-0.572650</td>\n",
              "      <td>-0.857143</td>\n",
              "      <td>0.098901</td>\n",
              "      <td>0.797980</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>0.286486</td>\n",
              "      <td>0.298507</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.362319</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>-0.33913</td>\n",
              "      <td>0.325153</td>\n",
              "      <td>0.114504</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>-0.238095</td>\n",
              "      <td>-0.818182</td>\n",
              "      <td>-0.389967</td>\n",
              "      <td>0.407558</td>\n",
              "      <td>-0.230462</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>-0.242282</td>\n",
              "      <td>-0.814433</td>\n",
              "      <td>ABOVE_12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 231 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   PATIENT_VISIT_IDENTIFIER  AGE_ABOVE65  ...    WINDOW  ICU\n",
              "0                         0            1  ...       0-2    0\n",
              "1                         0            1  ...       2-4    0\n",
              "2                         0            1  ...       4-6    0\n",
              "3                         0            1  ...      6-12    0\n",
              "4                         0            1  ...  ABOVE_12    1\n",
              "\n",
              "[5 rows x 231 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw1v8gL6wj-i"
      },
      "source": [
        "#FUNÇÕES BÁSICAS - Preparação dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z30xS1boxCZw"
      },
      "source": [
        "Abaixo temos funções que realizarão as limpezas iniciais dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSeda6p935ej"
      },
      "source": [
        "Função usada para nos mostrar um breve resumo do nosso DataFrame (Usada no notebook Visualizando dados)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu_fWN5g4C_Q"
      },
      "source": [
        "def resume_dataframe(dataset  : pd.DataFrame):\r\n",
        "  \r\n",
        "  data_nan = dataset.isnull().any().any() #retorno os dados Not a Number das colunas\r\n",
        "  dataset_types = list (set(dataset.dtypes.values)) #com o set realizo um \"filtro\" removendo dados repetidos\r\n",
        "  print(\"################ RESUMO BÁSICO ####################\\n\")\r\n",
        "  #shape nos retorna uma tupla com dois valores, sendo um referente a linhas e o outro a coluna, respectivamente.\r\n",
        "  print(f\"Quantidade de instâncias: {dataset.shape[0]} (linhas)\\nQuantidade de Atributos: {dataset.shape[1]} (colunas)\\n\")\r\n",
        "\r\n",
        "  if data_nan:\r\n",
        "    print(f\"Possui dados NaN ? {data_nan}\\nQuantidade de NaN totais: {dataset.isnull().sum().values.sum()}\\n\")\r\n",
        "  else:\r\n",
        "    print(\"Não há dados ausentes neste dataset\\n\")\r\n",
        "\r\n",
        "  print(f\"Tipos de  dados que temos :\\n{dataset_types}\\n\")\r\n",
        "  print(\"##################################################\\n\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyjYE5fOxV0o"
      },
      "source": [
        "Essa função divide nosso dataframe em 3 pedaços:\r\n",
        "* features continuas (contém grande parte das colunas de dados clínicos e NaN)\r\n",
        "* features categoricas (as 13 primeiras colunas do nosso DataFrame)\r\n",
        "* saida (as duas últimas colunas  - `WINDOW`e `ICU`)\r\n",
        "\r\n",
        "Aplica-se groupby para agrupar cada valor da coluna `PATIENT_VISIT_IDENTIFIER` e nela, aplicar, para as colunas continuas selecionadas, os métodos `bfill`e `fill` para assim preencher os dados faltantesm uma vez que por serem relacionados a saúde, não apresentam, no geral, grandes discrepâncias. Por último, agrupamos tudo novamente e reajustamos as colunas, por fim retornando os dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cOOj_6NtO_D"
      },
      "source": [
        "def preenche_tabela(dados):\r\n",
        "    features_continuas_colunas = dados.iloc[:, 13:-2].columns\r\n",
        "    features_continuas = dados.groupby(\"PATIENT_VISIT_IDENTIFIER\", as_index=False)[features_continuas_colunas]\\\r\n",
        "                          .fillna(method='bfill')\\\r\n",
        "                          .fillna(method='ffill')\r\n",
        "    features_categoricas = dados.iloc[:, :13]\r\n",
        "    saida = dados.iloc[:, -2:]\r\n",
        "    dados_finais = pd.concat([features_categoricas, features_continuas, saida], ignore_index=True,axis=1)\r\n",
        "    dados_finais.columns = dados.columns\r\n",
        "    return dados_finais"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmmfYZuDzgUq"
      },
      "source": [
        "Como trabalharemos com dados referentes a uma janela de até duas horas após a admissão, buscaremos filtrar e adicionar o valor 1 para pacientes que em algum momento foram para a UTI. Conforme explicado no notebook anterior (caso não tenha visto):<br>\r\n",
        ">Essa função é responsável por realizar um filtro do qual busca-se manter valores referentes a janela de até 2 duas horas. Aplicando-se esta função em um groupby, ocorrerá que os dados serão agrupados. Uma vez agrupados, faremos, por meio desta função, uma verificação onde se qualquer uma das linhas conferidas for igual a 1, ou seja, se em um agrupamento do paciente **x** em todos os períodos, se, por exemplo, na janela `0-4`, tivermos o valor de `ICU` == 1  (ou seja, um valor True), será aplicado nessa linha, da primeira janela de admissão (no caso, 0-2), o valor igual a 1 para a coluna ICU. Visualizando:\r\n",
        "\r\n",
        "\r\n",
        "| WINDOW  |ICU   |   \r\n",
        "|---------|------|\r\n",
        "| 0-2        | 0  | \r\n",
        "|     2-4    |  0 | \r\n",
        "|       4-6  |   1| \r\n",
        "|       6-12  |   0| \r\n",
        "\r\n",
        ">Veja como na janela de 4-6 horas, o paciente já foi para UTI. o que esta função fará é por o valor 1 logo na primeira Janela:\r\n",
        "\r\n",
        "| WINDOW  |ICU   |   \r\n",
        "|---------|------|\r\n",
        "| 0-2        | 1  | \r\n",
        "|     2-4    |  0 | \r\n",
        "|       4-6  |   0| \r\n",
        "|       6-12  |   0|\r\n",
        "\r\n",
        ">E assim, retornaremos apenas a primeira linha."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM_1aN0t0po-"
      },
      "source": [
        "Essa função agrupa todos os grupos de dados de um paciente e atribui o valor ICU == 1 na janela de até duas horas para assim pordemos trabalhar apenas com pacientes do quadro de até duas horas. Eis o motivo de termos jogado fora dados de pacientes com `ICU = 1` e `WINDOW = 0-2` logo de cara. Se a pessoa já entrou no hospital precisando de UTI, seus dados não servirão para o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyX8hyQGwqGb"
      },
      "source": [
        "def prepare_window(rows):\r\n",
        "    if(np.any(rows[\"ICU\"])):\r\n",
        "        rows.loc[rows[\"WINDOW\"]==\"0-2\", \"ICU\"] = 1\r\n",
        "    return rows.loc[rows[\"WINDOW\"] == \"0-2\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u8VY_JzWuoS"
      },
      "source": [
        "Nessa função, o que acontece é que passando nosso dataframe (contendo NaN e strings - não se preocupe quanto a isso), filtramos as colunas e ficamos apenas com as que são numéricas. Depois passamos o método de correlação e damos um .`pipe()` (com ele, a gente pode aplicar funções no DataFrame, por exemplo). Aplicamos um lambda e passamos um `np.tril()`. O que ele fará é retornar os valores maiores que -1 numa matrix de diagonal `k-therizada` (Leia a [documentação](https://numpy.org/doc/stable/reference/generated/numpy.tril.html) para um maior aprofundamento). Criamos as colunas e index e empilhamos as colunas que são geradas durante a correlação. Passando outro `pipe()`, retornamos apenas os valores que são maiores que o parâmetro que passamos na declaração da função. Por último damos um `query()` para realizar um filtro em valores que estão na coluna `level_0` e não em `level_1` ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INzjM6PbWuwp"
      },
      "source": [
        "def correlated_columns_harrison(dataset, threshold = 0.95):\r\n",
        "  df = dataset[dataset.describe().columns]  #fica-se apenas com as colunas que possuem valores numéricos\r\n",
        "  return (\r\n",
        "      df.corr().pipe(lambda df1: pd.DataFrame(np.tril(df1,k=-1),  \r\n",
        "                                              columns = df.columns,\r\n",
        "                                              index = df.columns,\r\n",
        "                                              )\r\n",
        "      ) \r\n",
        "      .stack()\r\n",
        "      .rename(\"pearson\")\r\n",
        "      .pipe(\r\n",
        "          lambda s: s[s.abs() >threshold].reset_index()\r\n",
        "      )\r\n",
        "      .query(\"level_0 not in level_1\")\r\n",
        "  )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQCKVLFPXGr7"
      },
      "source": [
        "Nessa função, iremos criar uma lista com as colunas com valores correlacionados que serão descartadas. Para as duas colunas que ela possui, iremos dropar valores repetidos e adicionar os que sobram a uma lista que é retornada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAyHLWeSXG04"
      },
      "source": [
        "def descartar_colunas_correlacionadas(dataset: pd.DataFrame):\r\n",
        "    colunas_com_muita_correlacao = [] #cria-se uma lista vazia \r\n",
        "    for valor in dataset['level_0'].drop_duplicates().values: #dropa-se o nome duplicados de colunsa presentes na coluna level_0\r\n",
        "      colunas_com_muita_correlacao.append(valor) #adiciona-se os valores na lista\r\n",
        "    for valor in dataset['level_1'].drop_duplicates().values:#dropa-se o nome duplicados de colunsa presentes na coluna level_1\r\n",
        "      colunas_com_muita_correlacao.append(valor)  #adiciona-se os valores na lista\r\n",
        "    return colunas_com_muita_correlacao"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_5mGNNoaUFV"
      },
      "source": [
        "Técnica elaborada por Thiago Gonçalves e Alan Spadinni, conhecida popularmente na literatura alurística de programação como **tecnica Gondinni**, que consiste na criação de correlação de todas as linhas e, com exceção das primeiras 4 e últimas duas colunas do dataframe,  gerar a correlação  e transformação dos valores para absoluto. Depois busca-se selecionar os valores do *triângulo superior* que foram gerados nessa matriz de correlação, todos os valores são transformados para 1s, e depois aplicamos um k = 1 (que gera a divisão dos valores do triângulo superior),, é que aplicamos uma transformação para True nos valores que antes eram 1 , e False para os valores  0s. Dessa forma, quando aplicado o `where`, conseguiremos pegar os valores da matriz superior e assim termos as colunas correlacionas, sem ter a parte do triângulo inferior, que funciona como um espelho. <BR>\r\n",
        "Por último, realizando um list comprehenssion, buscaremos todas as colunas maiores que `valor_corte` e adicionamos a `excluir` que será  usada para dropar posteriormente todas as colunas maiores que o valor setado para `valor_corte`.\r\n",
        "\r\n",
        "<img src = \"https://static.mundoeducacao.uol.com.br/mundoeducacao/conteudo/matriz-triangular-superior.jpg\">\r\n",
        "\r\n",
        "Acima temos um exemplo de uma matriz onde de azul são os valores da diagonal (em azul) que sempre serão iguais a 1, pois são as mesmas colunas refletidas uma na outras , como por exemplo  COLUNA_1 X COLUNA_1 , onde ambas são a mesma coluna, logo é obvio que irão ter correlação perfeita igual a 1. <br>\r\n",
        "Em preto, temos o chamado triângulo superior, que é o que desejamos manter, e em vermelho, o chamado triângulo inferior, que será descartado por possuir os mesmos resultados do outro triângulo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVXXW2waaUMO"
      },
      "source": [
        "def remove_corr_var(dados,valor_corte = .95):\r\n",
        "\r\n",
        "  matriz_corr = dados.iloc[:,4:-2].corr().abs()\r\n",
        "  matrix_upper = matriz_corr.where(np.triu(np.ones(matriz_corr.shape),k=1).astype(np.bool))\r\n",
        "  excluir  = [ coluna for coluna in matrix_upper.columns if any(matrix_upper[coluna] > valor_corte)]\r\n",
        "\r\n",
        "  return dados.drop(excluir,axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPsQ1Fz7Gnt7"
      },
      "source": [
        "Essa função irá executar os modelos:\r\n",
        "* DummyClassifier\r\n",
        "* LogisticRegression\r\n",
        "* DecisionTreeClassifier\r\n",
        "* KNeighborsClassifier\r\n",
        "* GaussianNB\r\n",
        "* SVC\r\n",
        "* RandomForestClassifier\r\n",
        "* XGBClassifier\r\n",
        "\r\n",
        "Passamos apenas o dataset que deverá ser particionado em treino e teste, depois com um laço de repetição, iremos obter os resultados de cada modelo para determinado conjunto de dados passados. A ideia é apenas ter uma visão inicial de como os dados estão funcionando, se logo de cara, já estão treinando bem, por isso não é passado parâmetros mais específicos para cada modelo, o que pode ocasionar a saída de **WARNINGS**. Contudo, pelos motivos explicados, isso é previsto. Por fim, temos a saída de uma lista com os valores AUC, desvio padrão (STD), e o tempo de execução."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeOuSEMoGn9v"
      },
      "source": [
        "def rodar_varios_modelos(dataset):\r\n",
        "  \r\n",
        "  x_columns = dataset.columns\r\n",
        "  x_columns = x_columns.drop([\"PATIENT_VISIT_IDENTIFIER\"])\r\n",
        "  y = dataset[\"ICU\"]\r\n",
        "  x = dataset[x_columns].drop([\"ICU\"], axis=1)\r\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y)\r\n",
        "\r\n",
        "  results = []\r\n",
        "  np.random.seed(415645)\r\n",
        "  for model in [DummyClassifier,LogisticRegression,DecisionTreeClassifier,KNeighborsClassifier,GaussianNB,\r\n",
        "                SVC,RandomForestClassifier,XGBClassifier]:\r\n",
        "\r\n",
        "                start_time  = time.time()\r\n",
        "\r\n",
        "                model_used = model()\r\n",
        "\r\n",
        "                kfold = StratifiedKFold(n_splits=5,shuffle=True)\r\n",
        "                val_score = model_selection.cross_val_score(model_used,x,y,scoring=\"roc_auc\",\r\n",
        "                                                            cv = kfold,)\r\n",
        "                \r\n",
        "                results.append(f\"{model.__name__:22} AUC:\\\r\n",
        "                {val_score.mean():.3f} STD: {val_score.std():.2f}     Tempo execução: {time.time() - start_time} seconds\")\r\n",
        "\r\n",
        "  return results"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pubBUIBJz_hu"
      },
      "source": [
        "# PREPARANDO O DATAFRAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5DAChSM4bcK"
      },
      "source": [
        "Antes de aplicar os modelos e ver qual possui melhor custo benefício, vamos preparar nosso dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a2l9bMM03bX"
      },
      "source": [
        "Cria-se a variável que armazanerá os dados formatados e previamente, limpos. Aqui, iremos também, realizar uma query por todas as colunas as linhas que possuem `WINDOW=='0-2' and ICU==1`, pois essas, serão eliminadas de imediado, dados que seus dados não nos servem. Realizamos um dropna para remover dados NaN restantes, caso haja."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "RRWoiczDwqEC",
        "outputId": "c843f51b-1ca5-4cff-c278-3dc550ca64d7"
      },
      "source": [
        "dados_limpos = preenche_tabela(dados)\r\n",
        "a_remover = dados_limpos.query(\"WINDOW=='0-2' and ICU==1\")['PATIENT_VISIT_IDENTIFIER'].values\r\n",
        "dados_limpos = dados_limpos.query(\"PATIENT_VISIT_IDENTIFIER not in @a_remover\")\r\n",
        "dados_limpos = dados_limpos.dropna()\r\n",
        "dados_limpos.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PATIENT_VISIT_IDENTIFIER</th>\n",
              "      <th>AGE_ABOVE65</th>\n",
              "      <th>AGE_PERCENTIL</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>DISEASE GROUPING 1</th>\n",
              "      <th>DISEASE GROUPING 2</th>\n",
              "      <th>DISEASE GROUPING 3</th>\n",
              "      <th>DISEASE GROUPING 4</th>\n",
              "      <th>DISEASE GROUPING 5</th>\n",
              "      <th>DISEASE GROUPING 6</th>\n",
              "      <th>HTN</th>\n",
              "      <th>IMMUNOCOMPROMISED</th>\n",
              "      <th>OTHER</th>\n",
              "      <th>ALBUMIN_MEDIAN</th>\n",
              "      <th>ALBUMIN_MEAN</th>\n",
              "      <th>ALBUMIN_MIN</th>\n",
              "      <th>ALBUMIN_MAX</th>\n",
              "      <th>ALBUMIN_DIFF</th>\n",
              "      <th>BE_ARTERIAL_MEDIAN</th>\n",
              "      <th>BE_ARTERIAL_MEAN</th>\n",
              "      <th>BE_ARTERIAL_MIN</th>\n",
              "      <th>BE_ARTERIAL_MAX</th>\n",
              "      <th>BE_ARTERIAL_DIFF</th>\n",
              "      <th>BE_VENOUS_MEDIAN</th>\n",
              "      <th>BE_VENOUS_MEAN</th>\n",
              "      <th>BE_VENOUS_MIN</th>\n",
              "      <th>BE_VENOUS_MAX</th>\n",
              "      <th>BE_VENOUS_DIFF</th>\n",
              "      <th>BIC_ARTERIAL_MEDIAN</th>\n",
              "      <th>BIC_ARTERIAL_MEAN</th>\n",
              "      <th>BIC_ARTERIAL_MIN</th>\n",
              "      <th>BIC_ARTERIAL_MAX</th>\n",
              "      <th>BIC_ARTERIAL_DIFF</th>\n",
              "      <th>BIC_VENOUS_MEDIAN</th>\n",
              "      <th>BIC_VENOUS_MEAN</th>\n",
              "      <th>BIC_VENOUS_MIN</th>\n",
              "      <th>BIC_VENOUS_MAX</th>\n",
              "      <th>BIC_VENOUS_DIFF</th>\n",
              "      <th>BILLIRUBIN_MEDIAN</th>\n",
              "      <th>BILLIRUBIN_MEAN</th>\n",
              "      <th>...</th>\n",
              "      <th>DIMER_MAX</th>\n",
              "      <th>DIMER_DIFF</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MEAN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MEAN</th>\n",
              "      <th>HEART_RATE_MEAN</th>\n",
              "      <th>RESPIRATORY_RATE_MEAN</th>\n",
              "      <th>TEMPERATURE_MEAN</th>\n",
              "      <th>OXYGEN_SATURATION_MEAN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MEDIAN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MEDIAN</th>\n",
              "      <th>HEART_RATE_MEDIAN</th>\n",
              "      <th>RESPIRATORY_RATE_MEDIAN</th>\n",
              "      <th>TEMPERATURE_MEDIAN</th>\n",
              "      <th>OXYGEN_SATURATION_MEDIAN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MIN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MIN</th>\n",
              "      <th>HEART_RATE_MIN</th>\n",
              "      <th>RESPIRATORY_RATE_MIN</th>\n",
              "      <th>TEMPERATURE_MIN</th>\n",
              "      <th>OXYGEN_SATURATION_MIN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MAX</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MAX</th>\n",
              "      <th>HEART_RATE_MAX</th>\n",
              "      <th>RESPIRATORY_RATE_MAX</th>\n",
              "      <th>TEMPERATURE_MAX</th>\n",
              "      <th>OXYGEN_SATURATION_MAX</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_DIFF</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_DIFF</th>\n",
              "      <th>HEART_RATE_DIFF</th>\n",
              "      <th>RESPIRATORY_RATE_DIFF</th>\n",
              "      <th>TEMPERATURE_DIFF</th>\n",
              "      <th>OXYGEN_SATURATION_DIFF</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_DIFF_REL</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_DIFF_REL</th>\n",
              "      <th>HEART_RATE_DIFF_REL</th>\n",
              "      <th>RESPIRATORY_RATE_DIFF_REL</th>\n",
              "      <th>TEMPERATURE_DIFF_REL</th>\n",
              "      <th>OXYGEN_SATURATION_DIFF_REL</th>\n",
              "      <th>WINDOW</th>\n",
              "      <th>ICU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.994912</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.283019</td>\n",
              "      <td>-0.593220</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.283019</td>\n",
              "      <td>-0.586207</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.237113</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.162393</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>-0.247863</td>\n",
              "      <td>-0.459459</td>\n",
              "      <td>-0.432836</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>-0.420290</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0-2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.994912</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.132075</td>\n",
              "      <td>-0.593220</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.132075</td>\n",
              "      <td>-0.586207</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.443299</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.025641</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.838384</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>-0.459459</td>\n",
              "      <td>-0.313433</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>0.246377</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>2-4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.994912</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.243021</td>\n",
              "      <td>-0.338537</td>\n",
              "      <td>-0.213031</td>\n",
              "      <td>-0.317859</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-0.283951</td>\n",
              "      <td>-0.376923</td>\n",
              "      <td>-0.188679</td>\n",
              "      <td>-0.379310</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-0.340206</td>\n",
              "      <td>-0.4875</td>\n",
              "      <td>-0.572650</td>\n",
              "      <td>-0.857143</td>\n",
              "      <td>0.318681</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>0.286486</td>\n",
              "      <td>0.298507</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>-0.275362</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-0.33913</td>\n",
              "      <td>0.325153</td>\n",
              "      <td>0.114504</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.389967</td>\n",
              "      <td>0.407558</td>\n",
              "      <td>-0.230462</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>4-6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.979069</td>\n",
              "      <td>-0.979069</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.996762</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.243021</td>\n",
              "      <td>-0.338537</td>\n",
              "      <td>-0.213031</td>\n",
              "      <td>-0.317859</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-0.283951</td>\n",
              "      <td>-0.376923</td>\n",
              "      <td>-0.188679</td>\n",
              "      <td>-0.379310</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-0.340206</td>\n",
              "      <td>-0.4875</td>\n",
              "      <td>-0.572650</td>\n",
              "      <td>-0.857143</td>\n",
              "      <td>0.318681</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>0.286486</td>\n",
              "      <td>0.298507</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>-0.275362</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-0.33913</td>\n",
              "      <td>0.325153</td>\n",
              "      <td>0.114504</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.389967</td>\n",
              "      <td>0.407558</td>\n",
              "      <td>-0.230462</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>6-12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.979069</td>\n",
              "      <td>-0.979069</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.996762</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.243021</td>\n",
              "      <td>-0.338537</td>\n",
              "      <td>-0.213031</td>\n",
              "      <td>-0.317859</td>\n",
              "      <td>0.033779</td>\n",
              "      <td>0.665932</td>\n",
              "      <td>-0.283951</td>\n",
              "      <td>-0.376923</td>\n",
              "      <td>-0.188679</td>\n",
              "      <td>-0.379310</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>-0.340206</td>\n",
              "      <td>-0.4875</td>\n",
              "      <td>-0.572650</td>\n",
              "      <td>-0.857143</td>\n",
              "      <td>0.098901</td>\n",
              "      <td>0.797980</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>0.286486</td>\n",
              "      <td>0.298507</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.362319</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>-0.33913</td>\n",
              "      <td>0.325153</td>\n",
              "      <td>0.114504</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>-0.238095</td>\n",
              "      <td>-0.818182</td>\n",
              "      <td>-0.389967</td>\n",
              "      <td>0.407558</td>\n",
              "      <td>-0.230462</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>-0.242282</td>\n",
              "      <td>-0.814433</td>\n",
              "      <td>ABOVE_12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 231 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   PATIENT_VISIT_IDENTIFIER  AGE_ABOVE65  ...    WINDOW  ICU\n",
              "0                         0            1  ...       0-2    0\n",
              "1                         0            1  ...       2-4    0\n",
              "2                         0            1  ...       4-6    0\n",
              "3                         0            1  ...      6-12    0\n",
              "4                         0            1  ...  ABOVE_12    1\n",
              "\n",
              "[5 rows x 231 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxNisY7j2TbZ"
      },
      "source": [
        "Possuímos dados Categóricos em nosso conjunto de dados. Logo, ainda precisamos limpar mais, antes de começarmos a aplicar algum modelo. As colunas `AGE_PERCENTIL`e `WINDOW` possuem informações do tipo **String** que precisam ser categorizadas de forma a não gerar uma discrepância alta de valores e assim influenciar de forma errada nosso modelo. Digo isso pois, a aplicação de um `.astype(\"category\").cat.codes` resultaria em valores iguais a 5,3, 2 e assim em diante, e nossos estão normalizados. Buscando resolver isso, aplico um `pd.get_dummies` para que seja criada uma coluna para cada valor, sendo preenchido de 0s e 1s. Observe também que antes de realizar isso, na linha acima, em `apply`, aplico a função `prepare window`. Ficamos então apenas com o quadro de até duas horas após a admissão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "3xasvoLAwv7P",
        "outputId": "335ff469-15eb-4497-cc73-a9569a0494ec"
      },
      "source": [
        "dados_limpos = dados_limpos.groupby(\"PATIENT_VISIT_IDENTIFIER\").apply(prepare_window)\r\n",
        "dados_limpos = pd.get_dummies(dados_limpos) \r\n",
        "dados_limpos.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>PATIENT_VISIT_IDENTIFIER</th>\n",
              "      <th>AGE_ABOVE65</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>DISEASE GROUPING 1</th>\n",
              "      <th>DISEASE GROUPING 2</th>\n",
              "      <th>DISEASE GROUPING 3</th>\n",
              "      <th>DISEASE GROUPING 4</th>\n",
              "      <th>DISEASE GROUPING 5</th>\n",
              "      <th>DISEASE GROUPING 6</th>\n",
              "      <th>HTN</th>\n",
              "      <th>IMMUNOCOMPROMISED</th>\n",
              "      <th>OTHER</th>\n",
              "      <th>ALBUMIN_MEDIAN</th>\n",
              "      <th>ALBUMIN_MEAN</th>\n",
              "      <th>ALBUMIN_MIN</th>\n",
              "      <th>ALBUMIN_MAX</th>\n",
              "      <th>ALBUMIN_DIFF</th>\n",
              "      <th>BE_ARTERIAL_MEDIAN</th>\n",
              "      <th>BE_ARTERIAL_MEAN</th>\n",
              "      <th>BE_ARTERIAL_MIN</th>\n",
              "      <th>BE_ARTERIAL_MAX</th>\n",
              "      <th>BE_ARTERIAL_DIFF</th>\n",
              "      <th>BE_VENOUS_MEDIAN</th>\n",
              "      <th>BE_VENOUS_MEAN</th>\n",
              "      <th>BE_VENOUS_MIN</th>\n",
              "      <th>BE_VENOUS_MAX</th>\n",
              "      <th>BE_VENOUS_DIFF</th>\n",
              "      <th>BIC_ARTERIAL_MEDIAN</th>\n",
              "      <th>BIC_ARTERIAL_MEAN</th>\n",
              "      <th>BIC_ARTERIAL_MIN</th>\n",
              "      <th>BIC_ARTERIAL_MAX</th>\n",
              "      <th>BIC_ARTERIAL_DIFF</th>\n",
              "      <th>BIC_VENOUS_MEDIAN</th>\n",
              "      <th>BIC_VENOUS_MEAN</th>\n",
              "      <th>BIC_VENOUS_MIN</th>\n",
              "      <th>BIC_VENOUS_MAX</th>\n",
              "      <th>BIC_VENOUS_DIFF</th>\n",
              "      <th>BILLIRUBIN_MEDIAN</th>\n",
              "      <th>BILLIRUBIN_MEAN</th>\n",
              "      <th>BILLIRUBIN_MIN</th>\n",
              "      <th>...</th>\n",
              "      <th>HEART_RATE_MEDIAN</th>\n",
              "      <th>RESPIRATORY_RATE_MEDIAN</th>\n",
              "      <th>TEMPERATURE_MEDIAN</th>\n",
              "      <th>OXYGEN_SATURATION_MEDIAN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MIN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MIN</th>\n",
              "      <th>HEART_RATE_MIN</th>\n",
              "      <th>RESPIRATORY_RATE_MIN</th>\n",
              "      <th>TEMPERATURE_MIN</th>\n",
              "      <th>OXYGEN_SATURATION_MIN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MAX</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MAX</th>\n",
              "      <th>HEART_RATE_MAX</th>\n",
              "      <th>RESPIRATORY_RATE_MAX</th>\n",
              "      <th>TEMPERATURE_MAX</th>\n",
              "      <th>OXYGEN_SATURATION_MAX</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_DIFF</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_DIFF</th>\n",
              "      <th>HEART_RATE_DIFF</th>\n",
              "      <th>RESPIRATORY_RATE_DIFF</th>\n",
              "      <th>TEMPERATURE_DIFF</th>\n",
              "      <th>OXYGEN_SATURATION_DIFF</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_DIFF_REL</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_DIFF_REL</th>\n",
              "      <th>HEART_RATE_DIFF_REL</th>\n",
              "      <th>RESPIRATORY_RATE_DIFF_REL</th>\n",
              "      <th>TEMPERATURE_DIFF_REL</th>\n",
              "      <th>OXYGEN_SATURATION_DIFF_REL</th>\n",
              "      <th>ICU</th>\n",
              "      <th>AGE_PERCENTIL_10th</th>\n",
              "      <th>AGE_PERCENTIL_20th</th>\n",
              "      <th>AGE_PERCENTIL_30th</th>\n",
              "      <th>AGE_PERCENTIL_40th</th>\n",
              "      <th>AGE_PERCENTIL_50th</th>\n",
              "      <th>AGE_PERCENTIL_60th</th>\n",
              "      <th>AGE_PERCENTIL_70th</th>\n",
              "      <th>AGE_PERCENTIL_80th</th>\n",
              "      <th>AGE_PERCENTIL_90th</th>\n",
              "      <th>AGE_PERCENTIL_Above 90th</th>\n",
              "      <th>WINDOW_0-2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PATIENT_VISIT_IDENTIFIER</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.283019</td>\n",
              "      <td>-0.586207</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.237113</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.162393</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>-0.247863</td>\n",
              "      <td>-0.459459</td>\n",
              "      <td>-0.432836</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>-0.420290</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <th>10</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.056604</td>\n",
              "      <td>-0.517241</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>-0.525773</td>\n",
              "      <td>-0.5125</td>\n",
              "      <td>-0.111111</td>\n",
              "      <td>-0.714286</td>\n",
              "      <td>0.604396</td>\n",
              "      <td>0.959596</td>\n",
              "      <td>-0.435897</td>\n",
              "      <td>-0.491892</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.575758</td>\n",
              "      <td>0.101449</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.547826</td>\n",
              "      <td>-0.533742</td>\n",
              "      <td>-0.603053</td>\n",
              "      <td>-0.764706</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.959596</td>\n",
              "      <td>-0.515528</td>\n",
              "      <td>-0.351328</td>\n",
              "      <td>-0.747001</td>\n",
              "      <td>-0.756272</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.961262</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <th>15</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.263158</td>\n",
              "      <td>-0.263158</td>\n",
              "      <td>-0.263158</td>\n",
              "      <td>-0.263158</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.972789</td>\n",
              "      <td>-0.972789</td>\n",
              "      <td>-0.972789</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.528302</td>\n",
              "      <td>-0.448276</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.175258</td>\n",
              "      <td>-0.1125</td>\n",
              "      <td>-0.384615</td>\n",
              "      <td>-0.357143</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>-0.299145</td>\n",
              "      <td>-0.556757</td>\n",
              "      <td>-0.626866</td>\n",
              "      <td>-0.515152</td>\n",
              "      <td>-0.420290</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <th>20</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.935113</td>\n",
              "      <td>-0.935113</td>\n",
              "      <td>-0.935113</td>\n",
              "      <td>...</td>\n",
              "      <td>0.160377</td>\n",
              "      <td>-0.586207</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.868421</td>\n",
              "      <td>0.443299</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.196581</td>\n",
              "      <td>-0.571429</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.939394</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>-0.351351</td>\n",
              "      <td>-0.044776</td>\n",
              "      <td>-0.575758</td>\n",
              "      <td>0.072464</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.877301</td>\n",
              "      <td>-0.923664</td>\n",
              "      <td>-0.882353</td>\n",
              "      <td>-0.952381</td>\n",
              "      <td>-0.979798</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.883669</td>\n",
              "      <td>-0.956805</td>\n",
              "      <td>-0.870968</td>\n",
              "      <td>-0.953536</td>\n",
              "      <td>-0.980333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <th>25</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.537736</td>\n",
              "      <td>-0.517241</td>\n",
              "      <td>-0.196429</td>\n",
              "      <td>0.815789</td>\n",
              "      <td>0.030928</td>\n",
              "      <td>-0.3750</td>\n",
              "      <td>-0.401709</td>\n",
              "      <td>-0.428571</td>\n",
              "      <td>0.252747</td>\n",
              "      <td>0.919192</td>\n",
              "      <td>-0.247863</td>\n",
              "      <td>-0.567568</td>\n",
              "      <td>-0.626866</td>\n",
              "      <td>-0.575758</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.842105</td>\n",
              "      <td>-0.826087</td>\n",
              "      <td>-0.754601</td>\n",
              "      <td>-0.984733</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.976190</td>\n",
              "      <td>-0.979798</td>\n",
              "      <td>-0.860870</td>\n",
              "      <td>-0.714460</td>\n",
              "      <td>-0.986481</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.975891</td>\n",
              "      <td>-0.980129</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 240 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             PATIENT_VISIT_IDENTIFIER  ...  WINDOW_0-2\n",
              "PATIENT_VISIT_IDENTIFIER                               ...            \n",
              "0                        0                          0  ...           1\n",
              "2                        10                         2  ...           1\n",
              "3                        15                         3  ...           1\n",
              "4                        20                         4  ...           1\n",
              "5                        25                         5  ...           1\n",
              "\n",
              "[5 rows x 240 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uibSFIrR3myl"
      },
      "source": [
        "Antes de iniciar a aplicação dos modelos de Machine Learning, vejamos o que temos nos dados agora:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzvtZF6r2JxD",
        "outputId": "671c9eec-6a68-4cd2-8a7a-088382b76e88"
      },
      "source": [
        "resume_dataframe(dados_limpos)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################ RESUMO BÁSICO ####################\n",
            "\n",
            "Quantidade de instâncias: 352 (linhas)\n",
            "Quantidade de Atributos: 240 (colunas)\n",
            "\n",
            "Não há dados ausentes neste dataset\n",
            "\n",
            "Tipos de  dados que temos :\n",
            "[dtype('uint8'), dtype('float64'), dtype('int64')]\n",
            "\n",
            "##################################################\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om1C3S9bVv7N"
      },
      "source": [
        "Possuimos então 240 colunas no total. Entretanto talvez não seja necessário o uso de todas essas colunas, dado que muitas colunas podem vir a atrapalhar as predições. Criarei dois dataframes, onde ambos buscarão excluir dados com alta correlação, mas onde ambos realizam tal tarefa de forma diferente. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPQIgcFskxH6"
      },
      "source": [
        "### 2 MÉTODOS PARA EXCLUIR DADOS CORRELACIONADOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSA7M1M1ZOq7"
      },
      "source": [
        "**Excluindo-se dados correlacionados com a técnica de Matt Harisson**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bCfmwRPWKzg"
      },
      "source": [
        "#cria-se um dataframe com 3 colunas(duas onde os valores são o nome de colunas e a terceira com os valores de correlação > .95)\r\n",
        "dados_correlacionados = correlated_columns_harrison(dados_limpos,.95)\r\n",
        "\r\n",
        "#filtra-se de ambas as colunas que possuem nomes aqueles que não se repetem, gerando uma lista\r\n",
        "excluir = descartar_colunas_correlacionadas(dados_correlacionados)\r\n",
        "\r\n",
        "#descarta-se as colunas com alta correlação\r\n",
        "dados_limpos_sem_corr_tipo_1 = dados_limpos.drop(excluir,axis=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6LMZpdEaCij",
        "outputId": "c020dec7-0973-492b-ce53-63b3598ab6e2"
      },
      "source": [
        "resume_dataframe(dados_limpos_sem_corr_tipo_1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################ RESUMO BÁSICO ####################\n",
            "\n",
            "Quantidade de instâncias: 352 (linhas)\n",
            "Quantidade de Atributos: 64 (colunas)\n",
            "\n",
            "Não há dados ausentes neste dataset\n",
            "\n",
            "Tipos de  dados que temos :\n",
            "[dtype('uint8'), dtype('float64'), dtype('int64')]\n",
            "\n",
            "##################################################\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_W23uZ6ZY-f"
      },
      "source": [
        "**Excluindo-se dados correlacionados com a técnica de Thiago Gonçalves e Alan Spadinni: técnica Gondinni**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvbXhieBWLHd"
      },
      "source": [
        "dados_limpos_sem_corr_tipo_2 = remove_corr_var(dados_limpos)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdYkXqn6aMiD",
        "outputId": "85983e61-4df0-4203-a833-cf7d360d521c"
      },
      "source": [
        "resume_dataframe(dados_limpos_sem_corr_tipo_2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################ RESUMO BÁSICO ####################\n",
            "\n",
            "Quantidade de instâncias: 352 (linhas)\n",
            "Quantidade de Atributos: 109 (colunas)\n",
            "\n",
            "Não há dados ausentes neste dataset\n",
            "\n",
            "Tipos de  dados que temos :\n",
            "[dtype('uint8'), dtype('float64'), dtype('int64')]\n",
            "\n",
            "##################################################\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJO-mnLzk4ma"
      },
      "source": [
        "Nota-se que em um método, temos 64 colunas, no outro, 109. \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcMYwa1fjb54"
      },
      "source": [
        "### DADOS A SEREM TREINADOS INICIALMENTE\r\n",
        "\r\n",
        ">Por fim, temos três variáveis referentes aos dados de pacientes:\r\n",
        "\r\n",
        "* `DADOS_LIMPOS` = **POSSUE TODAS AS COLUNAS (240)**\r\n",
        "* `DADOS_LIMPOS_SEM_CORR_TIPO_1` = **POSSUE COLUNAS SEM ALTA CORRELAÇÃO COM BASE NA TÉCNICA DE MATT HARISSON (64)**\r\n",
        "* `DADOS_LIMPOS_SEM_CORR_TIPO_2` = **POSSUE COLUNAS SEM ALTA CORRELAÇÃO COM BASE NA TÉCNICA GONDINNI (109)**\r\n",
        "\r\n",
        ">Todas as variáveis estão sem dados Not a Number (NaN) e serão usadas em todos os modelos para que possamos ver qual se desempenhará melhor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyYgpUub4SM0"
      },
      "source": [
        "# IMPLEMENTAÇÃO DE MODELOS DE APRENDIZAGEM DE MÁQUINA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10c84J__kbrm"
      },
      "source": [
        "Nosso projeto consiste na classificação de pacientes que devem ir para UTI ou não, com base em uma série de dados referentes a seus exames e sinais vitais. Para isso, nada melhor do que aplicar técnicas de aprendizagem de máquinas voltadas para classificação. Por conceito temos:\r\n",
        "\r\n",
        ">Os modelos de ML para problemas de classificação binária preveem um resultado binário (uma de duas classes possíveis).<br> ([link para referência](https://docs.aws.amazon.com/pt_br/machine-learning/latest/dg/types-of-ml-models.html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yakxcXyDugdp"
      },
      "source": [
        "No nosso caso, utilizarei os seguintes modelos:\r\n",
        "\r\n",
        "* DummyClassifier\r\n",
        "* LogisticRegression\r\n",
        "* DecisionTreeClassifier\r\n",
        "* KNeighborsClassifier\r\n",
        "* GaussianNB\r\n",
        "* SVC\r\n",
        "* RandomForestClassifier\r\n",
        "* XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXsjbe6eun3W"
      },
      "source": [
        "Contudo, apesar de uma breve explicação sobre cada um, não trabalharemos com todos. Iremos apenas inicialmente rodá-los e dependendo do desempenho, ficaremos com 4 ou 5 modelos para trabalhar. Logo, algumas coisas a se levar em conta:\r\n",
        "\r\n",
        "* Sua precisão, recall e acucácia;\r\n",
        "* Para que o modelo possa ser usado, ele deve possuir um custo-benefício bom o suficiente para entrar em produção. De nada serve um modelo 100% bom em classificar, mas que leva 2 horas para fazer isso (levando em conta que os dados crescerão com o tempo).\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfMElasuH2yc"
      },
      "source": [
        "Testando inicialmente os conjunto de dados com os modelos, mas sem especificar os parâmetros, temos:<br>\r\n",
        "***\r\n",
        "***\r\n",
        "**OBSERVAÇÃO**: desconsiderar avisos de warning\r\n",
        "***\r\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHsMqXyl-IBd"
      },
      "source": [
        "Rodando primeiramente para `dados_limpos`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0v768JFDCjB",
        "outputId": "cbb081a3-0afd-4d29-efc6-1bebbef880f3"
      },
      "source": [
        "resultados_dados_limpos = rodar_varios_modelos(dados_limpos)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpDtIJj9-U9J"
      },
      "source": [
        "Rodando para `dados_limpos_sem_corr_tipo_1`\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DD1JpRo61Ff",
        "outputId": "b15a7297-5804-43fe-a7b7-3a394ce51d4a"
      },
      "source": [
        "resultados_sem_corr_tipo_1 = rodar_varios_modelos(dados_limpos_sem_corr_tipo_1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXlSm_0O-acw"
      },
      "source": [
        "rodando em `dados_limpos_sem_corr_tipo_2`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhzm-qb57RSu",
        "outputId": "98cccfa8-f3b4-4ae5-c169-b7df30e73c0f"
      },
      "source": [
        "resultados_sem_corr_tipo_2 =rodar_varios_modelos(dados_limpos_sem_corr_tipo_2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csD5JFJ7-06n"
      },
      "source": [
        "#### Resultados iniciais para vários modelos e quais serão usados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6RE4aQVDFSF"
      },
      "source": [
        "#⭕ EXPLICAR PARÂMETROS AUC STD E TEMPO DE EXECUÇÃO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-DWcVta-5lY"
      },
      "source": [
        "Vejamos então como o filtro de dados realizados, auxiliarão no resultado final dos modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaXAqSlY_IVg",
        "outputId": "4735785c-6774-4e49-e4b5-7f1a8717689a"
      },
      "source": [
        "resultados_dados_limpos"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DummyClassifier        AUC:                0.502 STD: 0.06     Tempo execução: 0.03156781196594238 seconds',\n",
              " 'LogisticRegression     AUC:                0.740 STD: 0.03     Tempo execução: 0.3169217109680176 seconds',\n",
              " 'DecisionTreeClassifier AUC:                0.619 STD: 0.03     Tempo execução: 0.16098713874816895 seconds',\n",
              " 'KNeighborsClassifier   AUC:                0.655 STD: 0.06     Tempo execução: 0.10729098320007324 seconds',\n",
              " 'GaussianNB             AUC:                0.744 STD: 0.03     Tempo execução: 0.03814291954040527 seconds',\n",
              " 'SVC                    AUC:                0.769 STD: 0.08     Tempo execução: 0.2042384147644043 seconds',\n",
              " 'RandomForestClassifier AUC:                0.788 STD: 0.01     Tempo execução: 1.1148900985717773 seconds',\n",
              " 'XGBClassifier          AUC:                0.779 STD: 0.02     Tempo execução: 1.2634599208831787 seconds']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4X6Xhxn81pA",
        "outputId": "8bee3941-2f2a-410a-fcb6-67eea50fb0fe"
      },
      "source": [
        "resultados_sem_corr_tipo_1"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DummyClassifier        AUC:                0.502 STD: 0.06     Tempo execução: 0.02571845054626465 seconds',\n",
              " 'LogisticRegression     AUC:                0.712 STD: 0.09     Tempo execução: 0.2232053279876709 seconds',\n",
              " 'DecisionTreeClassifier AUC:                0.589 STD: 0.03     Tempo execução: 0.06094670295715332 seconds',\n",
              " 'KNeighborsClassifier   AUC:                0.670 STD: 0.04     Tempo execução: 0.06968116760253906 seconds',\n",
              " 'GaussianNB             AUC:                0.690 STD: 0.04     Tempo execução: 0.03141355514526367 seconds',\n",
              " 'SVC                    AUC:                0.694 STD: 0.06     Tempo execução: 0.08722448348999023 seconds',\n",
              " 'RandomForestClassifier AUC:                0.682 STD: 0.05     Tempo execução: 0.8508431911468506 seconds',\n",
              " 'XGBClassifier          AUC:                0.731 STD: 0.04     Tempo execução: 0.318737268447876 seconds']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc8i1VF8_EDM",
        "outputId": "f4ee4e3a-2292-43e2-c7e5-a5f560acfb70"
      },
      "source": [
        "resultados_sem_corr_tipo_2"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DummyClassifier        AUC:                0.502 STD: 0.06     Tempo execução: 0.0230560302734375 seconds',\n",
              " 'LogisticRegression     AUC:                0.750 STD: 0.04     Tempo execução: 0.2377936840057373 seconds',\n",
              " 'DecisionTreeClassifier AUC:                0.611 STD: 0.02     Tempo execução: 0.0920867919921875 seconds',\n",
              " 'KNeighborsClassifier   AUC:                0.698 STD: 0.06     Tempo execução: 0.07433938980102539 seconds',\n",
              " 'GaussianNB             AUC:                0.731 STD: 0.03     Tempo execução: 0.02962636947631836 seconds',\n",
              " 'SVC                    AUC:                0.754 STD: 0.09     Tempo execução: 0.11398029327392578 seconds',\n",
              " 'RandomForestClassifier AUC:                0.793 STD: 0.03     Tempo execução: 0.911909818649292 seconds',\n",
              " 'XGBClassifier          AUC:                0.776 STD: 0.02     Tempo execução: 0.5888965129852295 seconds']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Enq_I1B2_m-t"
      },
      "source": [
        "Ao que tudo indica, os modelos performaram melhor em:\r\n",
        "* `dados_limpos` (onde permaneceram a maior parte das colunas)\r\n",
        "* `dados_limpos_sem_corr_tipo_2` (Segundo o método GONDINNI)\r\n",
        "\r\n",
        "Além disso, no geral, os modelos que obtiveram bons resultados :\r\n",
        "* Logistic Regression\r\n",
        "* GaussianNB\r\n",
        "* SVC\r\n",
        "* Random Forest Classifier\r\n",
        "* XGBClassifier\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIBV6fevCZWj"
      },
      "source": [
        "Portanto, analisaremos estes modelos mais a fundo, apresentando uma breve explicação a cerca de seu funcionamento, e realizaremos alguns testes referentes a acerto, tempo de execução e processamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXDZc9fsDQL5"
      },
      "source": [
        "# 📊📖 Explicando Modelos escolhidos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t_5DTq_DUYT"
      },
      "source": [
        "Dado os modelos escolhidos, explicarei inicialmente um pouco de cada um, buscando não extender demais o tema para não perdermos o foco. Logo depois, iremos escolher quais resolvem melhor nosso problema, testar com tais modelos e determinar quais se saíram melhores, para no final, decidirmos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fimvRg2TDT_J"
      },
      "source": [
        "## 📕 Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joyzYRCqKw8e"
      },
      "source": [
        "Antes de explicar a **logistic regression** ou **regressão logistica**, é necessário compreender um pouco sobre regressão Linear. A **regressão Linear** é o processo de traçar uma reta através dos dados que são gerados através de um diagrama de dispersão. A partir daí, buscamos traçar uma equação que gere uma reta que nos mostre a relação existente nos dados.<br>\r\n",
        "A equação usada para buscar tal reta é :\r\n",
        "\\begin{equation}\r\n",
        "\\hat y = \\alpha + \\beta x + e\r\n",
        "\\end{equation}\r\n",
        "\r\n",
        "onde:\r\n",
        "* **x** : Variável independente que busca explicar y\r\n",
        "* **y**: Variável dependente a ser prevista\r\n",
        "* $\\alpha$ e $\\beta$ : são parâmetros de distribuição\r\n",
        "* $e$ : erros de medida\r\n",
        "\r\n",
        "Abaixo, temos um exemplo de regressão linear. Os pontos em vermelho representam nossos dados dispersos ao longo de um plano cartesiano em $R^2$ e em azul, temos uma reta que é gerada a partir de uma função que nós criamos derivada da equação de regressão linear.\r\n",
        "\r\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/LinearRegression.svg/1200px-LinearRegression.svg.png\" width=480>\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onVdMJQlRHB8"
      },
      "source": [
        "Assim, supondo que nosso objetivo fosse, a partir de uma base de dados, classificar a qualidade dos estudos de alunos de acordo com as horas de estudo e suas respectivas notas, poderiamos aplicar a regressão linear facilmente e assim buscar a probabilidade do aluno tirar uma nota $y$ baseado nas $x$ horas que ficou estudando."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLvmb1eQRi1k"
      },
      "source": [
        "Contudo, e se buscássemos saber qual a probabilidade de uma pessoa comprar um produto. Nossa variável resposta seria *comprar* e *não-comprar*. Com base em algumas variáveis como idade, salario e afins, como poderiamos classificar as pessoas que comprariam ou não o nosso produto, ou no caso do projeto, quais irão ou não precisar de UTI. Esse é um caso em que a regressão linear não nos ajudaria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4Bsx94nUoDK"
      },
      "source": [
        "Nesse caso, podemos então, aplicar uma regressão logistica, que apesar do nome, é na verdade um modelo linear de classificação. Neste modelo, as probabilidades que descrevem os possíveis resultados de um único ensaio são modeladas com o auxílio de uma função logística.<br>\r\n",
        "Equação da função logísticica:\r\n",
        "\\begin{equation}\r\n",
        "  f(x)={\\frac {L}{1+e^{-k(x-x_{0})}}}\\end{equation}\r\n",
        "\r\n",
        "onde:\r\n",
        "* $x_0$: valor do ponto médio do sigmoide;\r\n",
        "* $L$ : valor máximo da curva;\r\n",
        "* $K$: a taxa de crescimento logístico ou a inclinação da curva.\r\n",
        "\r\n",
        "Visualmente a função logística é assim:<br>\r\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIFuas0fXtTk"
      },
      "source": [
        "A regressão logística é um recurso que nos permite estimar\r\n",
        "a probabilidade associada à ocorrência de determinado\r\n",
        "evento em face de um conjunto de variáveis explanatórias.\r\n",
        "Como característica, Busca estimar a probabilidade da variável\r\n",
        "dependente assumir um determinado valor em\r\n",
        "função dos conhecidos de outras variáveis e os resultados da análise ficam contidos no\r\n",
        "intervalo de zero a um.\r\n",
        "<br>\r\n",
        "Na regressão logística, a probabilidade de ocorrência de um\r\n",
        "evento pode ser estimada diretamente. No caso da variável\r\n",
        "dependente\r\n",
        "Y assumir apenas dois possíveis estados (1 ou 0)\r\n",
        "e\r\n",
        "haver um conjunto de\r\n",
        "p variáveis independentes\r\n",
        "X1 , X2 , ... , Xp\r\n",
        ", o\r\n",
        "modelo de regressão logística pode ser escrito da seguinte forma:\r\n",
        "\r\n",
        "\\begin{equation}\r\n",
        "P\\big(Y = 1 ) = \\frac{1}{1 + e^{-g(x)}}\r\n",
        "\\end{equation}\r\n",
        "\r\n",
        "onde: \r\n",
        "\\begin{equation}\r\n",
        "g\\big(x\\big) = B_0 + B_1X_1 + ... B_pX_p\r\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqKcJ69mawLM"
      },
      "source": [
        "Abaixo temos um exemplo mostrando a dirença entre regressão linear e regressão logística:\r\n",
        "\r\n",
        "<img src= \"https://estatsite.com.br/wp-content/uploads/2018/08/1-3.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvddOkDNbX8a"
      },
      "source": [
        "Os pontos brancos em y=1 e y=0 podem ser interpretados como comprar e não-comprar, ou no nosso caso, precisa de UTI = 0, não precisa de UTI = 1. Veja como  a regressão logistica irá conseguir pegar um maior conjunto de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDNKWvHbcATq"
      },
      "source": [
        "## 📕 GaussianNB\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2uwHDqicraa"
      },
      "source": [
        "Implementa o algoritmo **Gaussian Naive Bayes** para classificação. Os métodos são baseados na aplicação do teorema de Bayes com a suposição \"ingênua\" de independência condicional entre cada par de características dado o valor da variável classe. O teorema de Bayes afirma a seguinte relação, dada a variável de classe e vetor de características dependentes através de $yx_1x_n$.\r\n",
        "\r\n",
        "\\begin{equation}\r\n",
        "P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) P(x_1, \\dots, x_n \\mid y)}\r\n",
        "                                 {P(x_1, \\dots, x_n)}\r\n",
        "\\end{equation}\r\n",
        "\r\n",
        "Baseado no “Teorema de Bayes”, o modelo foi criado por um matemático inglês, e também ministro presibiteriano, chamado Thomas Bayes (1701 – 1761) para tentar provar a existência de Deus.\r\n",
        "<br>\r\n",
        "Ele recebe o nome de “naive” (ingênuo) porque desconsidera a correlação entre as variáveis (features). Ou seja, se determinada fruta é rotulada como “Limão”, caso ela também seja descrita como “Verde” e “Redonda”, o algoritmo não vai levar em consideração a correlação entre esses fatores. Isso porque trata cada um de forma independente.<br>\r\n",
        "Entre as possibilidades de aplicações está a classificação de um e-mail como SPAM ou Não-SPAM e a identificação de um assunto com base em seu conteúdo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3oLp4gVf7bq"
      },
      "source": [
        "Segundo a documentação do **Sklearn**:\r\n",
        "> *Apesar de suas suposições aparentemente super simplificadas, os classificadores ingênuos de Bayes têm funcionado muito bem em muitas situações do mundo real, famosamente classificação de documentos e filtragem de spam. Eles requerem uma pequena quantidade de dados de treinamento para estimar os parâmetros necessários. [...] Embora  seja conhecido como um classificador decente, é conhecido por ser um estimador ruim, de modo que as saídas de probabilidade não devem ser levadas muito a sério.*\r\n",
        "\r\n",
        "Imagem de exemplo de seu comportamento:\r\n",
        "\r\n",
        "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_calibration_thumb.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlcNTKnFhBBa"
      },
      "source": [
        "## 📕 SVC - Support Vector Classification ou  Classificação vetorial de suporte.\r\n",
        "\r\n",
        "O **SVC**  é uma implementação diferente do mesmo algoritmo, **SVM** (Support Vector Machines ou máquinas vetoriais de suporte) que são  um conjunto de métodos de aprendizagem supervisionados utilizados para classificação, regressão e detecção de outliers. O SVM tem como vantagem:\r\n",
        " * Ser eficaz em espaços de alta dimensão;\r\n",
        " * Ainda eficaz nos casos em que o número de dimensões é maior do que o número de amostras.\r\n",
        "\r\n",
        "O SVM é definido como:\r\n",
        ">*é um algoritmo que busca uma linha de separação entre duas classes distintas analisando os dois pontos, um de cada grupo, mais próximos da outra classe. Isto é, o SVM escolhe a reta — também chamada de hiperplano em maiores dimensões— entre dois grupos que se distancia mais de cada um (no caso abaixo, a reta vermelha).*\r\n",
        "\r\n",
        "<img src=\"https://miro.medium.com/max/563/1*DW6xRZ9ylA3JMnlfNFuuBg.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGqTc21qhS5M"
      },
      "source": [
        "Os modelos SVM irão tentar encontrar uma separação linear entre as amostras do conjunto de dados.\r\n",
        "Um exemplo visual:\r\n",
        "<img src=\"https://www.machinecurve.com/wp-content/uploads/2020/05/dataset.png\" >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZg6XjHGpTqi"
      },
      "source": [
        "## 📕 Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NqP9qNQpXna"
      },
      "source": [
        "Random Forest ou Florestas aleatórias, é um algoritmo de aprendizagem supervisionado. Pode ser usado tanto para classificação quanto para regressão. É também o algoritmo mais flexível e fácil de usar. Uma floresta é composta por árvores. Diz-se que quanto mais árvores ela tem, mais robusta é uma floresta. Florestas aleatórias criam árvores de decisão em amostras de dados selecionadas aleatoriamente, obtém previsão de cada árvore e seleciona a melhor solução por meio de votação. Ele também fornece um indicador muito bom da importância do recurso. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehl5HMOTpXqR"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF_A-Yv8fQfp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6sAKq9HYGPb"
      },
      "source": [
        "#REFERÊNCIAS\r\n",
        "\r\n",
        "[Sklearn - Modelos Lineares](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)\r\n",
        "\r\n",
        "[Regressão Logística - Prof. Adriana Silva](https://www.youtube.com/watch?v=dcsZsA_wipE&ab_channel=EstaTiDados)\r\n",
        "\r\n",
        "[Modelos de Predição | Regressão Logística](https://medium.com/turing-talks/turing-talks-14-modelo-de-predi%C3%A7%C3%A3o-regress%C3%A3o-log%C3%ADstica-7b70a9098e43)\r\n",
        "[edisciplinas - usp](https://edisciplinas.usp.br/pluginfile.php/3769787/mod_resource/content/1/09_RegressaoLogistica.pdf)\r\n",
        "\r\n",
        "[Sklearn - 1.9 Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes)\r\n",
        "\r\n",
        "[Data Geeks - Classificação com Naive Bayes](https://www.datageeks.com.br/naive-bayes/)\r\n",
        "\r\n",
        "\r\n",
        "[Modelos de Predição| SVM](https://medium.com/turing-talks/turing-talks-12-classifica%C3%A7%C3%A3o-por-svm-f4598094a3f1)\r\n",
        "\r\n",
        "[Creating a simple binary SVM classifier with python and Scikit-learn](https://www.machinecurve.com/index.php/2020/05/03/creating-a-simple-binary-svm-classifier-with-python-and-scikit-learn/#choosing-a-kernel-function)\r\n",
        "\r\n",
        "\r\n",
        "[Entendendo classificadores de florestas aleatórias em Python](https://www.datacamp.com/community/tutorials/random-forests-classifier-python)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgElb37BfMPG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}